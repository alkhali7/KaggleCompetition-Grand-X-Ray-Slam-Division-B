{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:11:30.885351Z","iopub.execute_input":"2025-10-07T00:11:30.885720Z","iopub.status.idle":"2025-10-07T00:11:36.741960Z","shell.execute_reply.started":"2025-10-07T00:11:30.885691Z","shell.execute_reply":"2025-10-07T00:11:36.740956Z"}},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import Sequence\nimport numpy as np, pandas as pd, os, cv2, gc\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:27:18.778049Z","iopub.execute_input":"2025-10-07T00:27:18.778361Z","iopub.status.idle":"2025-10-07T00:27:18.793053Z","shell.execute_reply.started":"2025-10-07T00:27:18.778341Z","shell.execute_reply":"2025-10-07T00:27:18.792198Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:18.254063Z","iopub.execute_input":"2025-10-07T00:43:18.254551Z","iopub.status.idle":"2025-10-07T00:43:18.264414Z","shell.execute_reply.started":"2025-10-07T00:43:18.254525Z","shell.execute_reply":"2025-10-07T00:43:18.263005Z"}},"outputs":[{"name":"stdout","text":"['grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:18.772349Z","iopub.execute_input":"2025-10-07T00:43:18.773128Z","iopub.status.idle":"2025-10-07T00:43:18.997726Z","shell.execute_reply.started":"2025-10-07T00:43:18.773093Z","shell.execute_reply":"2025-10-07T00:43:18.996938Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# # 🧹 Clean up columns before K-Fold split\n# drop_cols = [\"Patient_ID\", \"Study\"]     # irrelevant for model\n# train = train.drop(columns=drop_cols)\n\n# print(\"✅ Dropped Patient_ID and Study columns.\")\n# print(f\"Remaining columns: {list(train.columns)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:38:15.583695Z","iopub.execute_input":"2025-10-07T00:38:15.584006Z","iopub.status.idle":"2025-10-07T00:38:15.596740Z","shell.execute_reply.started":"2025-10-07T00:38:15.583985Z","shell.execute_reply":"2025-10-07T00:38:15.595794Z"}},"outputs":[{"name":"stdout","text":"✅ Dropped Patient_ID and Study columns.\nRemaining columns: ['Image_name', 'Sex', 'Age', 'ViewCategory', 'ViewPosition', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:21.921245Z","iopub.execute_input":"2025-10-07T00:43:21.921593Z","iopub.status.idle":"2025-10-07T00:43:22.011272Z","shell.execute_reply.started":"2025-10-07T00:43:21.921569Z","shell.execute_reply":"2025-10-07T00:43:22.010279Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:22.584987Z","iopub.execute_input":"2025-10-07T00:43:22.585316Z","iopub.status.idle":"2025-10-07T00:43:22.590922Z","shell.execute_reply.started":"2025-10-07T00:43:22.585291Z","shell.execute_reply":"2025-10-07T00:43:22.589581Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to \nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:24.807595Z","iopub.execute_input":"2025-10-07T00:43:24.808031Z","iopub.status.idle":"2025-10-07T00:43:24.830219Z","shell.execute_reply.started":"2025-10-07T00:43:24.807993Z","shell.execute_reply":"2025-10-07T00:43:24.828869Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# #3 \n# # =============================================================\n# # ⚖️ Multi-Label Stratified K-Fold Split (balances rare diseases + view angles)\n# # =============================================================\n\n# mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# folds = []  # store train/val DataFrames\n\n# for fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n#     print(f\"\\n================ FOLD {fold+1} ================\")\n#     train_df = train.iloc[train_idx].reset_index(drop=True)\n#     val_df   = train.iloc[val_idx].reset_index(drop=True)\n#     folds.append((train_df, val_df))\n\n#     # Check label + view balance\n#     print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n#     print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n#     print(\"  Train label sums:\", train_df[conditions].sum().to_dict())\n#     print(\"  Val label sums:\", val_df[conditions].sum().to_dict())\n#     print(\"-\"*60)\n\n# # ✅ Use first fold for training (you can change to fold[1], fold[2], etc.)\n# train_df, val_df = folds[0]\n# print(f\"\\n✅ Selected Fold 1 — Train {train_df.shape}, Val {val_df.shape}\")\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n# =============================================================\n# 🧹 Clean dataset: drop identifiers\n# =============================================================\ndrop_cols = [\"Study\"]\ntrain = train.drop(columns=drop_cols)\nprint(\"✅ Dropped 'Study' column. Keeping 'Patient_ID' temporarily for grouping.\")\n\n# =============================================================\n# 🧩 Hybrid Multi-Label + Patient-Level Split\n# =============================================================\nunique_patients = train[\"Patient_ID\"].unique()\npatient_groups = train.groupby(\"Patient_ID\")[conditions].max().reset_index()\n\n# Stratify based on each patient’s condition profile\ny_patient = patient_groups[conditions].values\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfolds = []\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(unique_patients, y_patient)):\n    train_patients = unique_patients[train_idx]\n    val_patients   = unique_patients[val_idx]\n\n    train_df = train[train[\"Patient_ID\"].isin(train_patients)].reset_index(drop=True)\n    val_df   = train[train[\"Patient_ID\"].isin(val_patients)].reset_index(drop=True)\n\n    folds.append((train_df, val_df))\n\n    print(f\"\\n================ FOLD {fold+1} ================\")\n    print(f\" Train patients: {len(train_patients)} | Val patients: {len(val_patients)}\")\n    print(f\" Train images: {train_df.shape[0]} | Val images: {val_df.shape[0]}\")\n    print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"-\"*60)\n\n# ✅ Select first fold for training\ntrain_df, val_df = folds[0]\n\n# Drop Patient_ID now that split is done\ntrain_df = train_df.drop(columns=[\"Patient_ID\"])\nval_df = val_df.drop(columns=[\"Patient_ID\"])\n\nprint(f\"\\n✅ Selected Fold 1 — Train {train_df.shape}, Val {val_df.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:43:49.266291Z","iopub.execute_input":"2025-10-07T00:43:49.267006Z","iopub.status.idle":"2025-10-07T00:43:50.234033Z","shell.execute_reply.started":"2025-10-07T00:43:49.266976Z","shell.execute_reply":"2025-10-07T00:43:50.233274Z"}},"outputs":[{"name":"stdout","text":"✅ Dropped 'Study' column. Keeping 'Patient_ID' temporarily for grouping.\n\n================ FOLD 1 ================\n Train patients: 25704 | Val patients: 6373\n Train images: 87032 | Val images: 21462\n  Train views: {'Frontal': 76209, 'Lateral': 10823}\n  Val views: {'Frontal': 18805, 'Lateral': 2657}\n------------------------------------------------------------\n\n================ FOLD 2 ================\n Train patients: 25609 | Val patients: 6468\n Train images: 86566 | Val images: 21928\n  Train views: {'Frontal': 75814, 'Lateral': 10752}\n  Val views: {'Frontal': 19200, 'Lateral': 2728}\n------------------------------------------------------------\n\n================ FOLD 3 ================\n Train patients: 25672 | Val patients: 6405\n Train images: 86668 | Val images: 21826\n  Train views: {'Frontal': 75938, 'Lateral': 10730}\n  Val views: {'Frontal': 19076, 'Lateral': 2750}\n------------------------------------------------------------\n\n================ FOLD 4 ================\n Train patients: 25623 | Val patients: 6454\n Train images: 87016 | Val images: 21478\n  Train views: {'Frontal': 76208, 'Lateral': 10808}\n  Val views: {'Frontal': 18806, 'Lateral': 2672}\n------------------------------------------------------------\n\n================ FOLD 5 ================\n Train patients: 25700 | Val patients: 6377\n Train images: 86694 | Val images: 21800\n  Train views: {'Frontal': 75887, 'Lateral': 10807}\n  Val views: {'Frontal': 19127, 'Lateral': 2673}\n------------------------------------------------------------\n\n✅ Selected Fold 1 — Train (87032, 19), Val (21462, 19)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:44:19.719750Z","iopub.execute_input":"2025-10-07T00:44:19.720409Z","iopub.status.idle":"2025-10-07T00:44:19.733714Z","shell.execute_reply.started":"2025-10-07T00:44:19.720374Z","shell.execute_reply":"2025-10-07T00:44:19.732817Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"             Image_name     Sex   Age ViewCategory ViewPosition  Atelectasis  \\\n0  00000003_001_001.jpg    Male  41.0      Frontal           AP            0   \n1  00000004_001_001.jpg  Female  20.0      Frontal           PA            0   \n2  00000004_001_002.jpg  Female  20.0      Lateral      Lateral            0   \n3  00000006_001_001.jpg  Female  42.0      Frontal           AP            0   \n4  00000010_001_001.jpg  Female  50.0      Frontal           PA            0   \n\n   Cardiomegaly  Consolidation  Edema  Enlarged Cardiomediastinum  Fracture  \\\n0             1              0      1                           1         0   \n1             0              0      0                           0         0   \n2             0              0      0                           0         0   \n3             0              0      0                           0         0   \n4             0              0      0                           0         0   \n\n   Lung Lesion  Lung Opacity  No Finding  Pleural Effusion  Pleural Other  \\\n0            0             1           0                 0              0   \n1            0             0           1                 0              0   \n2            0             0           1                 0              0   \n3            0             0           1                 0              0   \n4            0             0           1                 0              0   \n\n   Pneumonia  Pneumothorax  Support Devices  \n0          0             0                0  \n1          0             0                0  \n2          0             0                0  \n3          0             0                0  \n4          0             0                0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"\n# =============================================================\n# ⚖️ Weighted Data Generator for Rare Classes\n# =============================================================\nclass XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False):\n        self.df = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.conditions = conditions\n        self.image_dir = (\n            \"/kaggle/input/grand-xray-slam-division-b/train2/\"\n            if not is_test\n            else \"/kaggle/input/grand-xray-slam-division-b/test2/\"\n        )\n\n        # Compute inverse-frequency sample weights   NEW\n        label_freq = self.df[self.conditions].sum().values + 1e-6\n        inv_freq = 1. / label_freq\n        self.sample_weights = (self.df[self.conditions].values * inv_freq).sum(axis=1)\n        self.sample_weights /= self.sample_weights.sum()\n\n    def __len__(self):\n        return len(self.df) // self.batch_size\n\n    def __getitem__(self, idx):\n        idxs = np.random.choice(len(self.df), self.batch_size, p=self.sample_weights)\n        batch = self.df.iloc[idxs]\n        images, labels = [], []\n\n        for _, row in batch.iterrows():\n            img_path = os.path.join(self.image_dir, row[\"Image_name\"])\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, self.img_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = img / 255.0\n            images.append(img)\n            if not self.is_test:\n                labels.append(row[self.conditions].values.astype(np.float32))\n\n        X = np.array(images, dtype=np.float32)\n        if self.is_test:\n            return X\n        else:\n            y = np.array(labels, dtype=np.float32)\n            return X, y\n\n# =============================================================\n# 🧮 Asymmetric Loss (for Long-Tailed Distribution)   NEW\n# =============================================================\ndef asymmetric_loss(gamma_pos=0, gamma_neg=4, clip=0.05):\n    def loss(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, clip, 1 - clip)\n        pos_loss = y_true * tf.math.log(y_pred) * (1 - y_pred) ** gamma_pos\n        neg_loss = (1 - y_true) * tf.math.log(1 - y_pred) * y_pred ** gamma_neg\n        return -tf.reduce_mean(pos_loss + neg_loss)\n    return loss\n\n# =============================================================\n# 🧱 ResNet50 + Custom Head\n# =============================================================\ndef build_resnet_model(num_classes=14):\n    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation=\"sigmoid\")(x)\n    model = Model(inputs=base_model.input, outputs=outputs)\n    return model\n\nmodel = build_resnet_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=asymmetric_loss(),\n    metrics=[tf.keras.metrics.AUC(name=\"AUC\")]\n)\nprint(\"✅ Model compiled successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:44:24.012658Z","iopub.execute_input":"2025-10-07T00:44:24.013497Z","iopub.status.idle":"2025-10-07T00:44:25.315785Z","shell.execute_reply.started":"2025-10-07T00:44:24.013454Z","shell.execute_reply":"2025-10-07T00:44:25.314966Z"}},"outputs":[{"name":"stdout","text":"✅ Model compiled successfully.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# =============================================================\n# ⚙️ Callbacks (robust against val_auc / val_AUC mismatch)\n# =============================================================\ncallbacks = [\n    ModelCheckpoint(\"best_resnet_model.h5\", monitor=\"val_auc\", mode=\"max\",\n                    save_best_only=True, verbose=1),\n    EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\",\n                  restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_auc\", factor=0.3, patience=2,\n                      mode=\"max\", min_lr=1e-6, verbose=1)\n]\n\n# Backup monitors to catch both metric names:\nalt_callbacks = [\n    ModelCheckpoint(\"best_resnet_model.h5\", monitor=\"val_AUC\", mode=\"max\",\n                    save_best_only=True, verbose=1),\n    EarlyStopping(monitor=\"val_AUC\", patience=3, mode=\"max\",\n                  restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_AUC\", factor=0.3, patience=2,\n                      mode=\"max\", min_lr=1e-6, verbose=1)\n]\n\n# =============================================================\n# 🚀 Training\n# =============================================================\nEPOCHS = 8\nBATCH_SIZE = 32\ntrain_gen = XRayDataGenerator(train_df, batch_size=BATCH_SIZE)\nval_gen   = XRayDataGenerator(val_df, batch_size=BATCH_SIZE)\n\nprint(\"🚀 Starting training...\")\ntry:\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=callbacks,\n        verbose=1\n    )\nexcept Exception as e:\n    print(\"⚠️ Switching to alternate callback metric (val_AUC).\")\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=alt_callbacks,\n        verbose=1\n    )\n\n# =============================================================\n# 🧾 Evaluate & Save Model\n# =============================================================\nhist = history.history\nval_auc = hist.get(\"val_auc\", [0])[-1] or hist.get(\"val_AUC\", [0])[-1]\nprint(f\"✅ Final Validation AUC: {val_auc:.4f}\")\n\nmodel.save(\"resnet50_final_longtail.h5\")\nprint(\"✅ Model saved as resnet50_final_longtail.h5\")\n\ngc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T00:44:27.314119Z","iopub.execute_input":"2025-10-07T00:44:27.314516Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting training...\nEpoch 1/8\n\u001b[1m  14/2719\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32:37\u001b[0m 3s/step - AUC: 0.4409 - loss: 0.5340","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
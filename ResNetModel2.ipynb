{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:09.282026Z","iopub.execute_input":"2025-10-07T01:27:09.282837Z","iopub.status.idle":"2025-10-07T01:27:17.493321Z","shell.execute_reply.started":"2025-10-07T01:27:09.282810Z","shell.execute_reply":"2025-10-07T01:27:17.492230Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.11/dist-packages (0.1.9)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import Sequence\nimport numpy as np, pandas as pd, os, cv2, gc\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:17.494935Z","iopub.execute_input":"2025-10-07T01:27:17.495302Z","iopub.status.idle":"2025-10-07T01:27:17.505785Z","shell.execute_reply.started":"2025-10-07T01:27:17.495268Z","shell.execute_reply":"2025-10-07T01:27:17.504673Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:17.507561Z","iopub.execute_input":"2025-10-07T01:27:17.507815Z","iopub.status.idle":"2025-10-07T01:27:17.538890Z","shell.execute_reply.started":"2025-10-07T01:27:17.507797Z","shell.execute_reply":"2025-10-07T01:27:17.537961Z"}},"outputs":[{"name":"stdout","text":"['grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:17.539896Z","iopub.execute_input":"2025-10-07T01:27:17.540164Z","iopub.status.idle":"2025-10-07T01:27:17.957955Z","shell.execute_reply.started":"2025-10-07T01:27:17.540141Z","shell.execute_reply":"2025-10-07T01:27:17.956898Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# 🧹 Clean up columns before K-Fold split\ndrop_cols = [\"Patient_ID\", \"Study\"]     # irrelevant for model\ntrain = train.drop(columns=drop_cols)\n\nprint(\"✅ Dropped Patient_ID and Study columns.\")\nprint(f\"Remaining columns: {list(train.columns)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:21.198675Z","iopub.execute_input":"2025-10-07T01:27:21.199668Z","iopub.status.idle":"2025-10-07T01:27:21.217398Z","shell.execute_reply.started":"2025-10-07T01:27:21.199632Z","shell.execute_reply":"2025-10-07T01:27:21.216404Z"}},"outputs":[{"name":"stdout","text":"✅ Dropped Patient_ID and Study columns.\nRemaining columns: ['Image_name', 'Sex', 'Age', 'ViewCategory', 'ViewPosition', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:22.375302Z","iopub.execute_input":"2025-10-07T01:27:22.376125Z","iopub.status.idle":"2025-10-07T01:27:22.482502Z","shell.execute_reply.started":"2025-10-07T01:27:22.376087Z","shell.execute_reply":"2025-10-07T01:27:22.481443Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:23.091610Z","iopub.execute_input":"2025-10-07T01:27:23.092825Z","iopub.status.idle":"2025-10-07T01:27:23.097880Z","shell.execute_reply.started":"2025-10-07T01:27:23.092784Z","shell.execute_reply":"2025-10-07T01:27:23.096934Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to \nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:27:24.574984Z","iopub.execute_input":"2025-10-07T01:27:24.575322Z","iopub.status.idle":"2025-10-07T01:27:24.611853Z","shell.execute_reply.started":"2025-10-07T01:27:24.575298Z","shell.execute_reply":"2025-10-07T01:27:24.610516Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#3 \n# =============================================================\n# ⚖️ Multi-Label Stratified K-Fold Split (balances rare diseases + view angles)\n# =============================================================\n\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfolds = []  # store train/val DataFrames\n\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    print(f\"\\n================ FOLD {fold+1} ================\")\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n    folds.append((train_df, val_df))\n\n    # Check label + view balance\n    print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Train label sums:\", train_df[conditions].sum().to_dict())\n    print(\"  Val label sums:\", val_df[conditions].sum().to_dict())\n    print(\"-\"*60)\n\n# ✅ Use irst fold for training (you can change to fold[1], fold[2], etc.)\ntrain_df, val_df = folds[0]\nprint(f\"\\n✅ Selected Fold 1 — Train {train_df.shape}, Val {val_df.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:28:30.112187Z","iopub.execute_input":"2025-10-07T01:28:30.112632Z","iopub.status.idle":"2025-10-07T01:28:33.006688Z","shell.execute_reply.started":"2025-10-07T01:28:30.112599Z","shell.execute_reply":"2025-10-07T01:28:33.005636Z"}},"outputs":[{"name":"stdout","text":"\n================ FOLD 1 ================\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train label sums: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27391, 'Pleural Effusion': 27655, 'Pleural Other': 5544, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val label sums: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6974, 'Pleural Effusion': 6914, 'Pleural Other': 1387, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\n\n================ FOLD 2 ================\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train label sums: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23716, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27668, 'Pleural Effusion': 27656, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val label sums: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5928, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6697, 'Pleural Effusion': 6913, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\n\n================ FOLD 3 ================\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train label sums: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27408, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11452, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val label sums: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6957, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2864, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n\n================ FOLD 4 ================\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train label sums: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27423, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val label sums: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6942, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n\n================ FOLD 5 ================\n  Train views: {'Frontal': 76012, 'Lateral': 10784}\n  Val views: {'Frontal': 19002, 'Lateral': 2696}\n  Train label sums: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30052, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27570, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val label sums: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7514, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6795, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n\n✅ Selected Fold 1 — Train (86795, 19), Val (21699, 19)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:28:35.528050Z","iopub.execute_input":"2025-10-07T01:28:35.528698Z","iopub.status.idle":"2025-10-07T01:28:35.543521Z","shell.execute_reply.started":"2025-10-07T01:28:35.528665Z","shell.execute_reply":"2025-10-07T01:28:35.542700Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"             Image_name     Sex   Age ViewCategory ViewPosition  Atelectasis  \\\n0  00000003_001_001.jpg    Male  41.0      Frontal           AP            0   \n1  00000004_001_001.jpg  Female  20.0      Frontal           PA            0   \n2  00000004_001_002.jpg  Female  20.0      Lateral      Lateral            0   \n3  00000006_001_001.jpg  Female  42.0      Frontal           AP            0   \n4  00000010_001_001.jpg  Female  50.0      Frontal           PA            0   \n\n   Cardiomegaly  Consolidation  Edema  Enlarged Cardiomediastinum  Fracture  \\\n0             1              0      1                           1         0   \n1             0              0      0                           0         0   \n2             0              0      0                           0         0   \n3             0              0      0                           0         0   \n4             0              0      0                           0         0   \n\n   Lung Lesion  Lung Opacity  No Finding  Pleural Effusion  Pleural Other  \\\n0            0             1           0                 0              0   \n1            0             0           1                 0              0   \n2            0             0           1                 0              0   \n3            0             0           1                 0              0   \n4            0             0           1                 0              0   \n\n   Pneumonia  Pneumothorax  Support Devices  \n0          0             0                0  \n1          0             0                0  \n2          0             0                0  \n3          0             0                0  \n4          0             0                0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# longggg time\n# =============================================================\n# ⚖️ Weighted Data Generator for Rare Classes\n# =============================================================\nclass XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False):\n        self.df = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.conditions = conditions\n        self.image_dir = (\n            \"/kaggle/input/grand-xray-slam-division-b/train2/\"\n            if not is_test\n            else \"/kaggle/input/grand-xray-slam-division-b/test2/\"\n        )\n\n        # Compute inverse-frequency sample weights   NEW\n        label_freq = self.df[self.conditions].sum().values + 1e-6\n        inv_freq = 1. / label_freq\n        self.sample_weights = (self.df[self.conditions].values * inv_freq).sum(axis=1)\n        self.sample_weights /= self.sample_weights.sum()\n\n    def __len__(self):\n        return len(self.df) // self.batch_size\n\n    def __getitem__(self, idx):\n        idxs = np.random.choice(len(self.df), self.batch_size, p=self.sample_weights)\n        batch = self.df.iloc[idxs]\n        images, labels = [], []\n\n        for _, row in batch.iterrows():\n            img_path = os.path.join(self.image_dir, row[\"Image_name\"])\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, self.img_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = img / 255.0\n            images.append(img)\n            if not self.is_test:\n                labels.append(row[self.conditions].values.astype(np.float32))\n\n        X = np.array(images, dtype=np.float32)\n        if self.is_test:\n            return X\n        else:\n            y = np.array(labels, dtype=np.float32)\n            return X, y\n\n# =============================================================\n# 🧮 Asymmetric Loss (for Long-Tailed Distribution)   NEW\n# =============================================================\ndef asymmetric_loss(gamma_pos=0, gamma_neg=4, clip=0.05):\n    def loss(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, clip, 1 - clip)\n        pos_loss = y_true * tf.math.log(y_pred) * (1 - y_pred) ** gamma_pos\n        neg_loss = (1 - y_true) * tf.math.log(1 - y_pred) * y_pred ** gamma_neg\n        return -tf.reduce_mean(pos_loss + neg_loss)\n    return loss\n\n# =============================================================\n# 🧱 ResNet50 + Custom Head\n# =============================================================\ndef build_resnet_model(num_classes=14):\n    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation=\"sigmoid\")(x)\n    model = Model(inputs=base_model.input, outputs=outputs)\n    return model\n\nmodel = build_resnet_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss=asymmetric_loss(),\n    metrics=[tf.keras.metrics.AUC(name=\"AUC\")]\n)\nprint(\"✅ Model compiled successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:28:52.552635Z","iopub.execute_input":"2025-10-07T01:28:52.553373Z","iopub.status.idle":"2025-10-07T01:28:54.942936Z","shell.execute_reply.started":"2025-10-07T01:28:52.553341Z","shell.execute_reply":"2025-10-07T01:28:54.942078Z"}},"outputs":[{"name":"stderr","text":"2025-10-07 01:28:52.583838: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"✅ Model compiled successfully.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================= looooong time\n# ⚙️ Callbacks (robust against val_auc / val_AUC mismatch)\n# =============================================================\ncallbacks = [\n    ModelCheckpoint(\"best_resnet_model.h5\", monitor=\"val_auc\", mode=\"max\",\n                    save_best_only=True, verbose=1),\n    EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\",\n                  restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_auc\", factor=0.3, patience=2,\n                      mode=\"max\", min_lr=1e-6, verbose=1)\n]\n\n# Backup monitors to catch both metric names:\nalt_callbacks = [\n    ModelCheckpoint(\"best_resnet_model.h5\", monitor=\"val_AUC\", mode=\"max\",\n                    save_best_only=True, verbose=1),\n    EarlyStopping(monitor=\"val_AUC\", patience=3, mode=\"max\",\n                  restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_AUC\", factor=0.3, patience=2,\n                      mode=\"max\", min_lr=1e-6, verbose=1)\n]\n\n# =============================================================\n# 🚀 Training\n# =============================================================\nEPOCHS = 4\nBATCH_SIZE = 32\ntrain_gen = XRayDataGenerator(train_df, batch_size=BATCH_SIZE)\nval_gen   = XRayDataGenerator(val_df, batch_size=BATCH_SIZE)\n\nprint(\"🚀 Starting training...\")\ntry:\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=callbacks,\n        verbose=1\n    )\nexcept Exception as e:\n    print(\"⚠️ Switching to alternate callback metric (val_AUC).\")\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS,\n        callbacks=alt_callbacks,\n        verbose=1\n    )\n# =============================================================\n# 🧾 Evaluate & Save Model\n# =============================================================\nhist = history.history\nval_auc = hist.get(\"val_auc\", [0])[-1] or hist.get(\"val_AUC\", [0])[-1]\nprint(f\"✅ Final Validation AUC: {val_auc:.4f}\")\n\nmodel.save(\"resnet50_final_longtail.h5\")\nprint(\"✅ Model saved as resnet50_final_longtail.h5\")\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T01:29:41.012086Z","iopub.execute_input":"2025-10-07T01:29:41.012512Z","iopub.status.idle":"2025-10-07T05:48:19.681931Z","shell.execute_reply.started":"2025-10-07T01:29:41.012482Z","shell.execute_reply":"2025-10-07T05:48:19.667604Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting training...\nEpoch 1/4\n\u001b[1m2712/2712\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - AUC: 0.7023 - loss: 0.2821⚠️ Switching to alternate callback metric (val_AUC).\nEpoch 1/4\n\u001b[1m1545/2712\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:08:28\u001b[0m 4s/step - AUC: 0.7558 - loss: 0.2601","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_102/3034161056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"⚠️ Switching to alternate callback metric (val_AUC).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nerror: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipykernel_102/1438863039.py\", line 35, in __getitem__\n    img = cv2.resize(img, self.img_size)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_11889]"],"ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nerror: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/tmp/ipykernel_102/1438863039.py\", line 35, in __getitem__\n    img = cv2.resize(img, self.img_size)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_11889]","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"Ω","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
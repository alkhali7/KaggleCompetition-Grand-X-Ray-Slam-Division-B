{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13253858,"sourceType":"datasetVersion","datasetId":8398667},{"sourceId":13271177,"sourceType":"datasetVersion","datasetId":8410247},{"sourceId":598793,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":448489,"modelId":464900}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet Model: \n1. Multi-Label Stratified K-Fold\n    - Multi-label imbalance handled: All rare diseases are proportionally represented.\n    - View imbalance handled: Each fold has close to the same Frontal/Lateral distribution.\n    - Sex & Age: Since they’re balanced already, we don’t need to augment stratification with them.\n\n2. Data Generator: (train ML model in batches to increase time efficiency, since training data >100gb)\n\n3. ResNet Model: fine tuned and pre-trained\n\n4. Train Model & Evaluate\n\nProblems and Solutions:\n- No internet pip loading in kaggle, couldn't load iterstat or imagenet pretrained weights for MultiLabelKfold Stratify and using pretrained weights for my ResNet model. **Solution**: Load iterstat package manually from github and use. Load resnet50 pretrained weights manually from keras into kaggle and load weights into resnet model.\n- fixed by verifying phone number on kaggle, now i can load iterstrat and imagenet pretrained weights\n","metadata":{}},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:10.406253Z","iopub.execute_input":"2025-10-05T18:51:10.406520Z","iopub.status.idle":"2025-10-05T18:51:28.369797Z","shell.execute_reply.started":"2025-10-05T18:51:10.406481Z","shell.execute_reply":"2025-10-05T18:51:28.369212Z"}},"outputs":[{"name":"stderr","text":"2025-10-05 18:51:15.994104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759690276.231613      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759690276.294811      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:39.763801Z","iopub.execute_input":"2025-10-05T18:51:39.764691Z","iopub.status.idle":"2025-10-05T18:51:39.770025Z","shell.execute_reply.started":"2025-10-05T18:51:39.764666Z","shell.execute_reply":"2025-10-05T18:51:39.769471Z"}},"outputs":[{"name":"stdout","text":"['resnet-pretrainedmodel', 'newresnet', 'iterstat', 'grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:48.075948Z","iopub.execute_input":"2025-10-05T18:51:48.076221Z","iopub.status.idle":"2025-10-05T18:51:48.428227Z","shell.execute_reply.started":"2025-10-05T18:51:48.076200Z","shell.execute_reply":"2025-10-05T18:51:48.427528Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# **Multi-Label Stratified Kfold**\n- Split to train and val data using multlabelKfold\n    - Multi-label imbalance handled: All rare diseases are proportionally represented.\n    - View imbalance handled: Each fold has close to the same Frontal/Lateral distribution.\n    - Sex & Age: Since they’re balanced already, we don’t need to augment stratification with them\n\n**Note**: cannot dowwnload iterstat pakcage on kaggle.\n1. Solution fetch and load Multi-Kfold stratification function in script manually, this way we get the same behavoir of stratification without the need of internet\n https://github.com/trent-b/iterative-stratification/blob/master/iterstrat/ml_stratifiers.py","metadata":{}},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:51.647676Z","iopub.execute_input":"2025-10-05T18:51:51.648354Z","iopub.status.idle":"2025-10-05T18:51:51.724528Z","shell.execute_reply.started":"2025-10-05T18:51:51.648329Z","shell.execute_reply":"2025-10-05T18:51:51.723765Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:52.069177Z","iopub.execute_input":"2025-10-05T18:51:52.069411Z","iopub.status.idle":"2025-10-05T18:51:52.073310Z","shell.execute_reply.started":"2025-10-05T18:51:52.069394Z","shell.execute_reply":"2025-10-05T18:51:52.072769Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to y\nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:51:52.794602Z","iopub.execute_input":"2025-10-05T18:51:52.795236Z","iopub.status.idle":"2025-10-05T18:51:52.816442Z","shell.execute_reply.started":"2025-10-05T18:51:52.795213Z","shell.execute_reply":"2025-10-05T18:51:52.815743Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:53:26.798350Z","iopub.execute_input":"2025-10-05T18:53:26.799069Z","iopub.status.idle":"2025-10-05T18:53:30.020987Z","shell.execute_reply.started":"2025-10-05T18:53:26.799036Z","shell.execute_reply":"2025-10-05T18:53:30.020056Z"}},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ml kaggle file that includes iterstat package (couldnt pip install iterstat in kaggle)\n# import sys\n# sys.path.append(\"/kaggle/input/iterstat/keras/default/1\")\n# from ml_stratifiers import MultilabelStratifiedKFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n# 3. Multilabel Stratified K-Fold Split\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    print(f\"Fold {fold}\")\n    print(\" Train:\", len(train_idx), \" Val:\", len(val_idx))\n\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n\n    # Check condition + view balance\n    print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Train labels sum:\", train_df[conditions].sum().to_dict())\n    print(\"  Val labels sum:\", val_df[conditions].sum().to_dict())\n    print(\"-\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:53:32.725949Z","iopub.execute_input":"2025-10-05T18:53:32.726591Z","iopub.status.idle":"2025-10-05T18:53:35.113830Z","shell.execute_reply.started":"2025-10-05T18:53:32.726554Z","shell.execute_reply":"2025-10-05T18:53:35.112984Z"}},"outputs":[{"name":"stdout","text":"Fold 0\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27391, 'Pleural Effusion': 27655, 'Pleural Other': 5544, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6974, 'Pleural Effusion': 6914, 'Pleural Other': 1387, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 1\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23716, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27668, 'Pleural Effusion': 27656, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5928, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6697, 'Pleural Effusion': 6913, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 2\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27408, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11452, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6957, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2864, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 3\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27423, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6942, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 4\n Train: 86796  Val: 21698\n  Train views: {'Frontal': 76012, 'Lateral': 10784}\n  Val views: {'Frontal': 19002, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30052, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27570, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7514, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6795, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(train_df.shape)\nprint(val_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:53:37.721868Z","iopub.execute_input":"2025-10-05T18:53:37.722579Z","iopub.status.idle":"2025-10-05T18:53:37.726556Z","shell.execute_reply.started":"2025-10-05T18:53:37.722547Z","shell.execute_reply":"2025-10-05T18:53:37.725741Z"}},"outputs":[{"name":"stdout","text":"(86796, 21)\n(21698, 21)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Data Generator\nTo handle large datasets, we use a custom generator to load images in batches.\n\nEach image is preprocessed with ResNet-50’s preprocessing function and resized to 224×224 (the default input size for ResNet-50).","metadata":{}},{"cell_type":"code","source":"class XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False, **kwargs):\n        super().__init__(**kwargs)\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.image_dir = '/kaggle/input/grand-xray-slam-division-b/train2/' if not is_test else '/kaggle/input/grand-xray-slam-division-b/test2/'\n        self.conditions = conditions\n        \n        if not os.path.exists(self.image_dir):\n            print(f\"Error: Directory {self.image_dir} not found.\")\n            raise FileNotFoundError(f\"Directory {self.image_dir} missing.\")\n    \n    def __len__(self):\n        return (len(self.dataframe) + self.batch_size - 1) // self.batch_size\n    \n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min(start + self.batch_size, len(self.dataframe))\n        batch_data = self.dataframe.iloc[start:end]\n        \n        images, labels = [], []\n        \n        for _, row in batch_data.iterrows():\n            img_path = os.path.join(self.image_dir, row['Image_name'])\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            \n            if img is not None and img.shape[0] > 0 and img.shape[1] > 0:\n                img = cv2.resize(img, self.img_size)\n                img = resnet.preprocess_input(img)\n                images.append(img)\n                \n                if not self.is_test:\n                    labels.append(row[self.conditions].values.astype(np.float32))\n        \n        if not images:\n            dummy_img = np.zeros((*self.img_size, 3), dtype=np.float32)\n            images.append(dummy_img)\n            if not self.is_test:\n                labels.append(np.zeros(len(self.conditions), dtype=np.float32))\n        \n        if not self.is_test:\n            return np.array(images), np.array(labels)\n        else:\n            return np.array(images)\n\n# Create generators\nbatch_size = 32\ntrain_generator = XRayDataGenerator(train_df, batch_size=batch_size)\nval_generator = XRayDataGenerator(val_df, batch_size=batch_size)\nprint(\"Data generators created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:53:46.310887Z","iopub.execute_input":"2025-10-05T18:53:46.311130Z","iopub.status.idle":"2025-10-05T18:53:46.326650Z","shell.execute_reply.started":"2025-10-05T18:53:46.311113Z","shell.execute_reply":"2025-10-05T18:53:46.326020Z"}},"outputs":[{"name":"stdout","text":"Data generators created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Build ResNet-50 Model¶\nWe load a pretrained ResNet-50 model with weights from ImageNet.\nThe convolutional base is frozen to retain pretrained features, and we add a custom classifier head:\n\n- Global Average Pooling to reduce feature maps.\n- Dense layer for feature learning.\n- Dropout to reduce overfitting.\n- Sigmoid output for multi-label classification across 14 chest conditions.","metadata":{}},{"cell_type":"code","source":"!ls -lh /kaggle/input/newresnet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:53:50.083554Z","iopub.execute_input":"2025-10-05T18:53:50.084236Z","iopub.status.idle":"2025-10-05T18:53:50.228655Z","shell.execute_reply.started":"2025-10-05T18:53:50.084214Z","shell.execute_reply":"2025-10-05T18:53:50.227559Z"}},"outputs":[{"name":"stdout","text":"total 91M\n-rw-r--r-- 1 nobody nogroup 91M Oct  5 17:08 resnet50_weights_tf_dim_ordering_tf_kernels_notop-2.h5\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import ResNet50\n\n# weights_path = '/kaggle/input/newresnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop-2.h5'\n\ndef build_resnet_model(num_classes=14):\n    # Load Resnet with cached ImageNet weights\n    base_model = ResNet50(\n        weights=\"imagenet\",  #doesnt work in kaggle\n        # weights = None,\n        include_top=False, \n        input_shape=(224, 224, 3)\n    )\n    # load pretrained weights manually\n    # print(\"Loading ResNet50 weights...\")\n    # base_model.load_weights(weights_path)\n    print(\"✅ Weights loaded successfully.\")\n    base_model.trainable = False   # freeze backbone for now\n    \n    # add custom head\n    inputs = base_model.input\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation=\"sigmoid\")(x)  # multilabel\n    \n    model = Model(inputs, outputs)\n    return model\n    \nmodel = build_resnet_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss=\"binary_crossentropy\",\n    metrics=[\"AUC\"]\n)\n\nprint(\"Model Architecture: ResNet50 + Custom Head\")\nprint(f\"Total parameters: {model.count_params():,}\")\ntrainable_params = sum([tf.size(v).numpy() for v in model.trainable_variables])\nprint(f\"Trainable parameters: {trainable_params:,}\")\nprint(f\"Non-trainable parameters: {model.count_params() - trainable_params:,}\")\nprint(\"Model compiled successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:55:01.061319Z","iopub.execute_input":"2025-10-05T18:55:01.061613Z","iopub.status.idle":"2025-10-05T18:55:07.881654Z","shell.execute_reply.started":"2025-10-05T18:55:01.061589Z","shell.execute_reply":"2025-10-05T18:55:07.880860Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1759690502.051856      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n✅ Weights loaded successfully.\nModel Architecture: ResNet50 + Custom Head\nTotal parameters: 24,115,854\nTrainable parameters: 528,142\nNon-trainable parameters: 23,587,712\nModel compiled successfully!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Train the Model\n- now we train the ResNet model for 3 epoch using the training and validation generators\n- the performance is tracked using AUC-ROC, which evaluates each of the 14 conditions","metadata":{}},{"cell_type":"code","source":"# Train for 3 epochs takes a long time\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=3,\n    verbose=1\n)\n\n# Display final validation AUC\nval_auc = history.history['val_AUC'][-1] if 'val_AUC' in history.history else 0.0\nprint(f\"Final Validation AUC-ROC: {val_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T17:33:34.943141Z","iopub.execute_input":"2025-10-05T17:33:34.943502Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m 710/2713\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:49:00\u001b[0m 3s/step - AUC: 0.7333 - loss: 0.5164","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Make Preditions or try better hyperparemeters and submit","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:56:28.661633Z","iopub.execute_input":"2025-10-05T18:56:28.662352Z","iopub.status.idle":"2025-10-05T18:56:28.666602Z","shell.execute_reply.started":"2025-10-05T18:56:28.662327Z","shell.execute_reply":"2025-10-05T18:56:28.665884Z"}},"outputs":[{"name":"stdout","text":"GPUs Available: 1\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================================\n# 🧠 GRAND X-RAY SLAM - RESNET50 FINAL TRAINING CELL\n# ============================================\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LambdaCallback\nfrom tensorflow.keras import mixed_precision\nimport os\n\n# ----------------------------------------\n# ⚙️ Enable mixed precision (Tensor Cores)\n# ----------------------------------------\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"✅ Mixed precision enabled for faster GPU performance.\")\n\n# ----------------------------------------\n# 🧩 Define callbacks for monitoring training\n# ----------------------------------------\ncheckpoint = ModelCheckpoint(\n    \"best_model.h5\",\n    monitor=\"val_auc\",       # monitor AUC metric\n    mode=\"max\",\n    save_best_only=True,\n    verbose=1\n)\n\nearly_stop = EarlyStopping(\n    monitor=\"val_auc\",\n    mode=\"max\",\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_auc\",\n    mode=\"max\",\n    factor=0.5,\n    patience=2,\n    min_lr=1e-6,\n    verbose=1\n)\n\n# ----------------------------------------\n# 🪄 Live plot callback (updates after each epoch)\n# ----------------------------------------\nhistory_data = {'auc': [], 'val_auc': [], 'loss': [], 'val_loss': []}\n\ndef on_epoch_end(epoch, logs):\n    history_data['auc'].append(logs.get('auc'))\n    history_data['val_auc'].append(logs.get('val_auc'))\n    history_data['loss'].append(logs.get('loss'))\n    history_data['val_loss'].append(logs.get('val_loss'))\n\n    # Clear previous plots\n    plt.clf()\n    plt.figure(figsize=(10,4))\n\n    # Plot AUC\n    plt.subplot(1,2,1)\n    plt.plot(history_data['auc'], label='Train AUC')\n    plt.plot(history_data['val_auc'], label='Val AUC')\n    plt.xlabel('Epochs'); plt.ylabel('AUC'); plt.legend(); plt.title('Training vs Validation AUC')\n\n    # Plot Loss\n    plt.subplot(1,2,2)\n    plt.plot(history_data['loss'], label='Train Loss')\n    plt.plot(history_data['val_loss'], label='Val Loss')\n    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.title('Training vs Validation Loss')\n\n    plt.tight_layout()\n    plt.show()\n\nlive_plot = LambdaCallback(on_epoch_end=on_epoch_end)\n\n# ----------------------------------------\n# 🧠 Compile model (from your build_resnet_model function)\n# ----------------------------------------\nprint(\"✅ Model compiled successfully.\")\nprint(f\"Total parameters: {model.count_params():,}\")\n\n# ----------------------------------------\n# 🚀 Train model\n# ----------------------------------------\nEPOCHS = 3   # increase later if needed\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=EPOCHS,\n    callbacks=[checkpoint, early_stop, reduce_lr, live_plot],\n    verbose=1,\n)\n\n# ----------------------------------------\n# 🧾 Evaluate and visualize results\n# ----------------------------------------\nval_auc = history.history.get('val_auc', [0])[-1]\nprint(f\"\\n✅ Final Validation AUC: {val_auc:.4f}\")\n\n# Save submission-ready model\nmodel.save(\"final_resnet_model.h5\")\nprint(\"✅ Model saved as final_resnet_model.h5\")\n\n# ----------------------------------------\n# 🔮 Predict on test set and create submission\n# ----------------------------------------\nprint(\"\\nGenerating predictions for submission...\")\nmodel.load_weights(\"best_model.h5\")  # best model from callbacks\ntest_generator = XRayDataGenerator(test_df, batch_size=32, is_test=True)\npreds = model.predict(test_generator, verbose=1)\n\nsubmission = pd.DataFrame(preds, columns=conditions)\nsubmission.insert(0, \"Image_name\", test_df[\"Image_name\"].values)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"✅ Submission file created successfully: submission.csv\")\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T18:58:04.429727Z","iopub.execute_input":"2025-10-05T18:58:04.429979Z"}},"outputs":[{"name":"stdout","text":"✅ Mixed precision enabled for faster GPU performance.\n✅ Model compiled successfully.\nTotal parameters: 24,115,854\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759690698.423282      91 service.cc:148] XLA service 0x7f0d08002b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1759690698.426310      91 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1759690700.025611      91 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/2713\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:24:52\u001b[0m 16s/step - AUC: 0.3602 - loss: 1.2275","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1759690704.364511      91 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 231/2713\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03:22\u001b[0m 2s/step - AUC: 0.6361 - loss: 0.6197","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
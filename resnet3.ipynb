{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"},{"sourceId":600891,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":450241,"modelId":466601}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet contineud\n- Load prev trained model, more epochs, decrease learning rate","metadata":{}},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:15.461913Z","iopub.execute_input":"2025-10-07T17:22:15.462891Z","iopub.status.idle":"2025-10-07T17:22:22.338751Z","shell.execute_reply.started":"2025-10-07T17:22:15.462859Z","shell.execute_reply":"2025-10-07T17:22:22.337274Z"}},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:22.340502Z","iopub.execute_input":"2025-10-07T17:22:22.340785Z","iopub.status.idle":"2025-10-07T17:22:47.867819Z","shell.execute_reply.started":"2025-10-07T17:22:22.340762Z","shell.execute_reply":"2025-10-07T17:22:47.866716Z"}},"outputs":[{"name":"stderr","text":"2025-10-07 17:22:24.762285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759857745.102370      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759857745.224746      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"GPUs Available: 0\n","output_type":"stream"},{"name":"stderr","text":"2025-10-07 17:22:47.863560: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:47.868994Z","iopub.execute_input":"2025-10-07T17:22:47.869843Z","iopub.status.idle":"2025-10-07T17:22:48.808788Z","shell.execute_reply.started":"2025-10-07T17:22:47.869819Z","shell.execute_reply":"2025-10-07T17:22:48.807529Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:48.811060Z","iopub.execute_input":"2025-10-07T17:22:48.811741Z","iopub.status.idle":"2025-10-07T17:22:48.828007Z","shell.execute_reply.started":"2025-10-07T17:22:48.811712Z","shell.execute_reply":"2025-10-07T17:22:48.826762Z"}},"outputs":[{"name":"stdout","text":"['newresnet1', 'grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:48.829767Z","iopub.execute_input":"2025-10-07T17:22:48.830117Z","iopub.status.idle":"2025-10-07T17:22:49.382867Z","shell.execute_reply.started":"2025-10-07T17:22:48.830084Z","shell.execute_reply":"2025-10-07T17:22:49.381727Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:49.384052Z","iopub.execute_input":"2025-10-07T17:22:49.384487Z","iopub.status.idle":"2025-10-07T17:22:49.487675Z","shell.execute_reply.started":"2025-10-07T17:22:49.384431Z","shell.execute_reply":"2025-10-07T17:22:49.486678Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:49.488804Z","iopub.execute_input":"2025-10-07T17:22:49.489095Z","iopub.status.idle":"2025-10-07T17:22:49.495167Z","shell.execute_reply.started":"2025-10-07T17:22:49.489073Z","shell.execute_reply":"2025-10-07T17:22:49.493684Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to \nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:49.496131Z","iopub.execute_input":"2025-10-07T17:22:49.496412Z","iopub.status.idle":"2025-10-07T17:22:49.538741Z","shell.execute_reply.started":"2025-10-07T17:22:49.496390Z","shell.execute_reply":"2025-10-07T17:22:49.537565Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"y_aug.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:23:23.047007Z","iopub.execute_input":"2025-10-07T17:23:23.048017Z","iopub.status.idle":"2025-10-07T17:23:23.054485Z","shell.execute_reply.started":"2025-10-07T17:23:23.047984Z","shell.execute_reply":"2025-10-07T17:23:23.053514Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(108494, 16)"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# MSKF","metadata":{}},{"cell_type":"code","source":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n# 3. Multilabel Stratified K-Fold Split\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfolds = []\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    print(f\"Fold {fold}\")\n    print(\" Train:\", len(train_idx), \" Val:\", len(val_idx))\n\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n\n    # Check condition + view balance\n    print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Train labels sum:\", train_df[conditions].sum().to_dict())\n    print(\"  Val labels sum:\", val_df[conditions].sum().to_dict())\n    print(\"-\"*60)\n    \n    folds.append((train_df, val_df))\n\n# Use first fold for training\ntrain_df, val_df = folds[0]\nprint(f\"✅ Selected Fold 1 — Train {train_df.shape}, Val {val_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:22:49.541944Z","iopub.execute_input":"2025-10-07T17:22:49.542476Z","iopub.status.idle":"2025-10-07T17:22:52.695063Z","shell.execute_reply.started":"2025-10-07T17:22:49.542342Z","shell.execute_reply":"2025-10-07T17:22:52.694004Z"}},"outputs":[{"name":"stdout","text":"Fold 0\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27391, 'Pleural Effusion': 27655, 'Pleural Other': 5544, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6974, 'Pleural Effusion': 6914, 'Pleural Other': 1387, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 1\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23716, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27668, 'Pleural Effusion': 27656, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5928, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6697, 'Pleural Effusion': 6913, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 2\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27408, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11452, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6957, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2864, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 3\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27423, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6942, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 4\n Train: 86796  Val: 21698\n  Train views: {'Frontal': 76012, 'Lateral': 10784}\n  Val views: {'Frontal': 19002, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30052, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27570, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7514, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6795, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n✅ Selected Fold 1 — Train (86795, 21), Val (21699, 21)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# data generator","metadata":{}},{"cell_type":"code","source":"class XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False, **kwargs):\n        super().__init__(**kwargs)\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.image_dir = '/kaggle/input/grand-xray-slam-division-b/train2/' if not is_test else '/kaggle/input/grand-xray-slam-division-b/test2/'\n        self.conditions = conditions\n        \n        if not os.path.exists(self.image_dir):\n            print(f\"Error: Directory {self.image_dir} not found.\")\n            raise FileNotFoundError(f\"Directory {self.image_dir} missing.\")\n    \n    def __len__(self):\n        return (len(self.dataframe) + self.batch_size - 1) // self.batch_size\n    \n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min(start + self.batch_size, len(self.dataframe))\n        batch_data = self.dataframe.iloc[start:end]\n        \n        images, labels = [], []\n        \n        for _, row in batch_data.iterrows():\n            img_path = os.path.join(self.image_dir, row['Image_name'])\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            \n            if img is not None and img.shape[0] > 0 and img.shape[1] > 0:\n                img = cv2.resize(img, self.img_size)\n                img = resnet.preprocess_input(img)\n                images.append(img)\n                \n                if not self.is_test:\n                    labels.append(row[self.conditions].values.astype(np.float32))\n        \n        if not images:\n            dummy_img = np.zeros((*self.img_size, 3), dtype=np.float32)\n            images.append(dummy_img)\n            if not self.is_test:\n                labels.append(np.zeros(len(self.conditions), dtype=np.float32))\n        \n        if not self.is_test:\n            return np.array(images), np.array(labels)\n        else:\n            return np.array(images)\n\n# Create generators\nbatch_size = 32\ntrain_generator = XRayDataGenerator(train_df, batch_size=batch_size)\nval_generator = XRayDataGenerator(val_df, batch_size=batch_size)\nprint(\"Data generators created.\")\n\n# Also define test_df (important for submission)\ntest_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/sample_submission_2.csv\")\ntest_df[\"Image_name\"] = test_df[\"Image_name\"].astype(str)\n\nprint(\"✅ Data generators ready — Train, Val, and Test loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:27:20.360608Z","iopub.execute_input":"2025-10-07T17:27:20.361773Z","iopub.status.idle":"2025-10-07T17:27:20.503910Z","shell.execute_reply.started":"2025-10-07T17:27:20.361740Z","shell.execute_reply":"2025-10-07T17:27:20.502663Z"}},"outputs":[{"name":"stdout","text":"Data generators created.\n✅ Data generators ready — Train, Val, and Test loaded.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# resnet improved ","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import ResNet50\n\ndef build_resnet_model(num_classes=14):\n    # Load Resnet with cached ImageNet weights\n    base_model = ResNet50(weights=\"imagenet\",  include_top=False, input_shape=(224, 224, 3))\n    \n    print(\"✅ Weights loaded successfully.\")\n    base_model.trainable = False   # freeze backbone for now\n    \n    # add custom head\n    inputs = base_model.input\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation=\"sigmoid\")(x)  # multilabel\n    \n    model = Model(inputs, outputs)\n    return model\n    \n# load resnet baseline model with AUC=0.87 public\nfrom tensorflow.keras.models import load_model\nmodel = build_resnet_model(num_classes=14)\nmodel.load_weights(\"/kaggle/input/newresnet1/keras/default/1/final_resnet_model.h5\")\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(name=\"auc\")]\n)\n\nprint(\"Model Architecture: ResNet50 + Custom Head\")\nprint(f\"Total parameters: {model.count_params():,}\")\ntrainable_params = sum([tf.size(v).numpy() for v in model.trainable_variables])\nprint(f\"Trainable parameters: {trainable_params:,}\")\nprint(f\"Non-trainable parameters: {model.count_params() - trainable_params:,}\")\nprint(\"Model compiled successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:33:38.141617Z","iopub.execute_input":"2025-10-07T17:33:38.141998Z","iopub.status.idle":"2025-10-07T17:33:42.180858Z","shell.execute_reply.started":"2025-10-07T17:33:38.141975Z","shell.execute_reply":"2025-10-07T17:33:42.179841Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n✅ Weights loaded successfully.\nModel Architecture: ResNet50 + Custom Head\nTotal parameters: 24,115,854\nTrainable parameters: 528,142\nNon-trainable parameters: 23,587,712\nModel compiled successfully!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\ncallbacks = [\n    ModelCheckpoint(\"resnet_finetune.weights.h5\", save_weights_only=True, save_best_only=True,\n                    monitor=\"val_auc\", mode=\"max\", verbose=1),\n    ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=2, mode=\"max\", verbose=1),\n    EarlyStopping(monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True)\n]\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=5,\n    verbose=1,\n    callbacks=callbacks\n)\nval_auc = history.history.get(\"val_auc\", [0])[-1]\nprint(f\"✅ Continued fine-tuning done — new Validation AUC ≈ {val_auc:.4f}\")\nmodel.save(\"final_resnet_finetuned.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T17:34:07.820713Z","iopub.execute_input":"2025-10-07T17:34:07.821003Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m  17/2713\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30:50\u001b[0m 3s/step - auc: 0.8697 - loss: 0.3239","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
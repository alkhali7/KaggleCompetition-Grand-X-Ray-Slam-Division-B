{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet50 Multi-label Xray Model \n1.  Architecture:\n- Uses ResNet50 (ImageNet-pretrained) as the feature extractor with a custom head:\n-  Global Average Pooling → Dense(256, ReLU) → Dropout(0.4) → Dense(14, Sigmoid).\n2. Data Loading:\n- Uses a custom XRayDataGenerator (OpenCV-based) for efficient image loading, resizing, and preprocessing.\n3. Optimization:\n- Mixed precision (float16) + XLA compilation for faster GPU performance.\n- CosineDecayRestarts learning-rate schedule.\n- Adam optimizer with binary cross-entropy loss.\n4. Training Strategy:\n- 2-fold Multilabel Stratified K-Fold CV for robust validation.\n5. Two-stage training:\n- Train top layers (frozen base).\n- Fine-tune last 20 ResNet layers.\n6. Callbacks:\n- ModelCheckpoint (saves best model by val_AUC) and EarlyStopping (patience=5).\n7. Output:\n- Saves each fold’s best/final models.\n- Creates an ensemble of 5 folds (average predictions).\nExports final submission.csv for Kaggle.","metadata":{}},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:53:09.565957Z","iopub.execute_input":"2025-10-06T04:53:09.566273Z","iopub.status.idle":"2025-10-06T04:53:13.081426Z","shell.execute_reply.started":"2025-10-06T04:53:09.566246Z","shell.execute_reply":"2025-10-06T04:53:13.080566Z"}},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:03.377226Z","iopub.execute_input":"2025-10-06T04:50:03.377713Z","iopub.status.idle":"2025-10-06T04:50:04.190559Z","shell.execute_reply.started":"2025-10-06T04:50:03.377692Z","shell.execute_reply":"2025-10-06T04:50:04.189772Z"}},"outputs":[{"name":"stdout","text":"GPUs Available: 1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nimport os, gc\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import CosineDecayRestarts\nfrom tensorflow.keras import mixed_precision\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nimport warnings\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T05:34:27.743962Z","iopub.execute_input":"2025-10-06T05:34:27.744330Z","iopub.status.idle":"2025-10-06T05:34:27.753668Z","shell.execute_reply.started":"2025-10-06T05:34:27.744308Z","shell.execute_reply":"2025-10-06T05:34:27.753013Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:42.222397Z","iopub.execute_input":"2025-10-06T04:50:42.222663Z","iopub.status.idle":"2025-10-06T04:50:42.229797Z","shell.execute_reply.started":"2025-10-06T04:50:42.222643Z","shell.execute_reply":"2025-10-06T04:50:42.229021Z"}},"outputs":[{"name":"stdout","text":"['grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:42.833735Z","iopub.execute_input":"2025-10-06T04:50:42.834026Z","iopub.status.idle":"2025-10-06T04:50:43.160050Z","shell.execute_reply.started":"2025-10-06T04:50:42.834005Z","shell.execute_reply":"2025-10-06T04:50:43.159243Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values\nprint(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:43.516750Z","iopub.execute_input":"2025-10-06T04:50:43.517055Z","iopub.status.idle":"2025-10-06T04:50:43.597784Z","shell.execute_reply.started":"2025-10-06T04:50:43.517032Z","shell.execute_reply":"2025-10-06T04:50:43.597014Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to \nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:44.696587Z","iopub.execute_input":"2025-10-06T04:50:44.697153Z","iopub.status.idle":"2025-10-06T04:50:44.717709Z","shell.execute_reply.started":"2025-10-06T04:50:44.697127Z","shell.execute_reply":"2025-10-06T04:50:44.717039Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Data Generator","metadata":{}},{"cell_type":"code","source":"# Data Generator (OpenCV based)\nclass XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False, **kwargs):\n        super().__init__(**kwargs)\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.image_dir = '/kaggle/input/grand-xray-slam-division-b/train2/' if not is_test else '/kaggle/input/grand-xray-slam-division-b/test2/'\n        self.conditions = conditions\n        \n        if not os.path.exists(self.image_dir):\n            raise FileNotFoundError(f\"Directory {self.image_dir} not found.\")\n    \n    def __len__(self):\n        return (len(self.dataframe) + self.batch_size - 1) // self.batch_size\n    \n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min(start + self.batch_size, len(self.dataframe))\n        batch_data = self.dataframe.iloc[start:end]\n        \n        images, labels = [], []\n        for _, row in batch_data.iterrows():\n            # image loading\n            img_path = os.path.join(self.image_dir, row['Image_name'])\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            \n            if img is not None:\n                # image augmentation: resize and preprocess using resnet\n                img = cv2.resize(img, self.img_size)\n                img = resnet.preprocess_input(img)\n                images.append(img)\n                if not self.is_test:\n                    labels.append(row[self.conditions].values.astype(np.float32))\n        \n        if not images:\n            images.append(np.zeros((*self.img_size, 3), dtype=np.float32))\n            if not self.is_test:\n                labels.append(np.zeros(len(self.conditions), dtype=np.float32))\n        \n        return (np.array(images), np.array(labels)) if not self.is_test else np.array(images)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T05:34:33.307556Z","iopub.execute_input":"2025-10-06T05:34:33.308207Z","iopub.status.idle":"2025-10-06T05:34:33.319841Z","shell.execute_reply.started":"2025-10-06T05:34:33.308180Z","shell.execute_reply":"2025-10-06T05:34:33.318830Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# ResNet \n**2-Fold stratified training with mixed precision, cosine LR schedule, and fine-tuning of top ResNet layers.\nUses custom OpenCV generator + ensemble of folds for strong, GPU-optimized AUC performance.**\n\n1. fold 1: 3 epochs frozen, 3 epochs trainable 20 layers saved as **fold_0_final.h5**\n2. fold 2: 3 epochs frozen, 3 epochs trainable 20 layers","metadata":{}},{"cell_type":"code","source":"# Enable GPU optimizations\ntf.config.optimizer.set_jit(True)\ntf.config.experimental.enable_tensor_float_32_execution(True)\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"✅ Mixed precision + XLA enabled for faster GPU performance.\")\n\nprint('**********Building ResNet Model******************')\n#  Build ResNet50 model\n# ============================================================\ndef build_resnet_model(num_classes=14, unfreeze_layers=None):\n    base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n    if unfreeze_layers:\n        for layer in base.layers[-unfreeze_layers:]:\n            layer.trainable = True\n    else:\n        base.trainable = False\n\n    x = tf.keras.layers.GlobalAveragePooling2D()(base.output)\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    out = tf.keras.layers.Dense(num_classes, activation=\"sigmoid\")(x)\n    return tf.keras.Model(inputs=base.input, outputs=out)\n\n# ============================================================\n# ⚙️ Callbacks\n# ============================================================\ndef get_callbacks(fold):\n    return [\n        ModelCheckpoint(f\"fold_{fold}_best.h5\", monitor=\"val_auc\", mode=\"max\", save_best_only=True, verbose=1),\n        EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=5, restore_best_weights=True, verbose=1),\n    ]\n\n# ============================================================\n#  Cross-validation training loop\n# ============================================================\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n# Try to load existing AUCs if you already ran some folds\ntry:\n    fold_aucs\nexcept NameError:\n    fold_aucs = []\nprint('**********Starting MSKF (k-fold) and CV training******************')\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\n# *********do two folds only************************** if fold >1: break\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    # skip already completed folds\n    if os.path.exists(f\"fold_{fold}_final.h5\"):\n        print(f\"✅ Skipping fold {fold} (already completed)\")\n        continue\n    if fold > 1:  # stop after fold 2\n        break\n    print(f\"\\n================ FOLD {fold+1} ================\")\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n\n    # Use generators\n    train_generator = XRayDataGenerator(train_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n    val_generator   = XRayDataGenerator(val_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n\n    # Learning rate schedule\n    lr_schedule = CosineDecayRestarts(\n        initial_learning_rate=1e-4,\n        first_decay_steps=len(train_generator)*2,\n        t_mul=2.0, m_mul=0.9, alpha=1e-6\n    )\n    # building resnet architecture \n    model = build_resnet_model() \n    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule), loss=\"binary_crossentropy\",\n        metrics=[tf.keras.metrics.AUC(name=\"auc\")]\n    )\n    # decrease epochs for less time\n    history = model.fit(\n        train_generator,validation_data=val_generator,\n        epochs=3, callbacks=get_callbacks(fold), verbose=1)\n\n    # Fine-tuning last 20 layers\n    for layer in model.layers[-20:]:\n        layer.trainable = True\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-5), loss=\"binary_crossentropy\",\n        metrics=[tf.keras.metrics.AUC(name=\"auc\")]\n    )\n    # decrease epochs for less time\n    history_ft = model.fit(\n        train_generator, validation_data=val_generator,\n        epochs=3, callbacks=get_callbacks(fold), verbose=1)\n\n    model.save(f\"fold_{fold}_final.h5\")\n    key = 'val_auc' if 'val_auc' in history.history else 'val_AUC'\n    best_auc = max(history.history[key] + history_ft.history[key])\n    fold_aucs.append(best_auc)\n    print(f\"✅ Fold {fold+1} Best AUC: {best_auc:.4f}\")\n    gc.collect()\n\nprint('*************************MSKF K-FOld COMPLETE*************')\n\n# ============================================================\n# 🧾 CV Summary\n# ============================================================\nprint(f\"\\n📊 Cross-validation AUCs: {fold_aucs}\")\nprint(f\"🏆 Mean CV AUC: {np.mean(fold_aucs):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T05:41:16.640713Z","iopub.execute_input":"2025-10-06T05:41:16.641030Z","iopub.status.idle":"2025-10-06T13:59:31.063769Z","shell.execute_reply.started":"2025-10-06T05:41:16.640969Z","shell.execute_reply":"2025-10-06T13:59:31.060892Z"}},"outputs":[{"name":"stdout","text":"✅ Mixed precision + XLA enabled for faster GPU performance.\n**********Building ResNet Model******************\n**********Starting MSKF (k-fold) and CV training******************\n\n================ FOLD 1 ================\nEpoch 1/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5030s\u001b[0m 2s/step - auc: 0.8180 - loss: 0.4265 - val_auc: 0.8922 - val_loss: 0.3453\nEpoch 2/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5067s\u001b[0m 2s/step - auc: 0.8814 - loss: 0.3543 - val_auc: 0.8957 - val_loss: 0.3400\nEpoch 3/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4941s\u001b[0m 2s/step - auc: 0.8842 - loss: 0.3575 - val_auc: 0.9007 - val_loss: 0.3325\nEpoch 1/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4921s\u001b[0m 2s/step - auc: 0.8899 - loss: 0.3441 - val_auc: 0.9008 - val_loss: 0.3381\nEpoch 2/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4971s\u001b[0m 2s/step - auc: 0.9081 - loss: 0.3196 - val_auc: 0.8955 - val_loss: 0.3434\nEpoch 3/3\n\u001b[1m2713/2713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4953s\u001b[0m 2s/step - auc: 0.9148 - loss: 0.3085 - val_auc: 0.8936 - val_loss: 0.3467\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3718404769.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fold_{fold}_final.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mbest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_AUC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_AUC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mfold_aucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Fold {fold+1} Best AUC: {best_auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_AUC'"],"ename":"KeyError","evalue":"'val_AUC'","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"best_auc = max(history.history['val_auc'] + history_ft.history['val_auc'])\n# fold_aucs.append(best_auc)\nprint(f\"✅ Fold {fold+1} Best AUC: {best_auc:.4f}\")\n\n# ============================================================\n# 🧾 CV Summary\n# ============================================================\nprint(f\"\\n📊 Cross-validation AUCs: {fold_aucs}\")\nprint(f\"🏆 Mean CV AUC: {np.mean(fold_aucs):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:26:25.440477Z","iopub.execute_input":"2025-10-06T14:26:25.441181Z","iopub.status.idle":"2025-10-06T14:26:25.445745Z","shell.execute_reply.started":"2025-10-06T14:26:25.441154Z","shell.execute_reply":"2025-10-06T14:26:25.445111Z"}},"outputs":[{"name":"stdout","text":"✅ Fold 1 Best AUC: 0.9008\n\n📊 Cross-validation AUCs: [0.9008244276046753]\n🏆 Mean CV AUC: 0.9008\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"print(history.history)   # 3 epochs frozen\nhistory_ft.history       # 3 epochs trained layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:26:05.522115Z","iopub.execute_input":"2025-10-06T14:26:05.522595Z","iopub.status.idle":"2025-10-06T14:26:05.527935Z","shell.execute_reply.started":"2025-10-06T14:26:05.522573Z","shell.execute_reply":"2025-10-06T14:26:05.527147Z"}},"outputs":[{"name":"stdout","text":"{'auc': [0.856939971446991, 0.8844783306121826, 0.8878996968269348], 'loss': [0.39033958315849304, 0.3552301526069641, 0.35056841373443604], 'val_auc': [0.89216548204422, 0.8957088589668274, 0.9007192254066467], 'val_loss': [0.34534314274787903, 0.3400052487850189, 0.33251953125]}\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'auc': [0.8944286108016968, 0.9066745042800903, 0.9145926833152771],\n 'loss': [0.3409472703933716, 0.32190805673599243, 0.30880698561668396],\n 'val_auc': [0.9008244276046753, 0.8954897522926331, 0.8935645818710327],\n 'val_loss': [0.3380545377731323, 0.343383252620697, 0.3467102348804474]}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# # Inferences\n# test_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/sample_submission_2.csv\")\n# test_df[\"Image_name\"] = test_df[\"Image_name\"].astype(str)\n# test_generator = XRayDataGenerator(test_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE, is_test=True)\n\n# fold_preds = []\n# for fold in range(2):\n\n#     m = tf.keras.models.load_model(f\"fold_{fold}_final.h5\", compile=False)\n#     fold_preds.append(m.predict(test_generator, verbose=1))\n\n# final_preds = np.mean(fold_preds, axis=0)\n# submission = pd.DataFrame(final_preds, columns=conditions)\n# submission.insert(0, \"Image_name\", test_df[\"Image_name\"].values)\n# submission.to_csv(\"submission.csv\", index=False)\n# print(\"✅ submission.csv created successfully!\")\n\n# Export robust TF SavedModel version\nmodel.export(\"fold_0_final_tf\")\nprint(\"✅ fold_0_final_tf/ folder created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:43:04.224778Z","iopub.execute_input":"2025-10-06T14:43:04.225393Z","iopub.status.idle":"2025-10-06T14:43:20.234949Z","shell.execute_reply.started":"2025-10-06T14:43:04.225371Z","shell.execute_reply":"2025-10-06T14:43:20.234270Z"}},"outputs":[{"name":"stdout","text":"Saved artifact at 'fold_0_final_tf'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_360')\nOutput Type:\n  TensorSpec(shape=(None, 14), dtype=tf.float16, name=None)\nCaptures:\n  140374833952912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833953488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833954448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833953680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833952336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833953296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095107664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095108240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095108432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095107280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095104976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095108048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095109968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095110544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095110736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095109584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095106128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095110352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095112272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095112848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140374833952720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095105936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095104592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095105360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095104784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095105744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095113040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095111888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095106512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095112656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095114576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095115152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095115344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095114192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095108816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095114960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095116880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095117456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095117648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095116496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095111120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095117264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095119184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095119760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095119952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095120720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095113424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095119568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095118032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095115728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095548304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095547344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095548112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095547152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095549840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095550416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095550608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095549456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095547536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095550224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095552144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095552720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095552912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095551760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095547920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095552528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095556752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095557328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095557520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095556368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095550992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095557136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095559056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095559632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095559824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095558672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095553296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095559440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095561360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095561936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095554448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095555024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095555216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095554064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095548688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095554832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095562128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095562896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095555600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095561744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095560592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373095562512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093942480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093941520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093942288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093941328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093944016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093944592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093944784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093943632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093941712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093944400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093946320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093946896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093947088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093945936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093942096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093946704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093948624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093949200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093949392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093948240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093942864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093949008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093950928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093951504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093951696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093950544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093945168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093951312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093953232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093953808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093954000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093952848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093947472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093953616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093955536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093956112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093956304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093955152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093949776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093955920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093954768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093957456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094417424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094416464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093952080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094416656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094418960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094419536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094419728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094418576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094416848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094419344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094423568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094424144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094424336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094423184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094417808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094423952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094425872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094426448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094426640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094425488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094420112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094426256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094428176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094428752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094421264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094421840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094422032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094420880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094417232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094421648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094428944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094427792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094422416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094428560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094430480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094431056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094431248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094430096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094424720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094430864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094427024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094431632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092795408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092794448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373094429712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092794640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092796752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092797328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092797520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092796368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092794832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092797136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092799056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092799632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092799824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092798672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092795600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092799440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092801360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092801936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092802128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092800976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092795216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092801744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092803664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092804240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092804432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092803280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092797904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092804048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092805968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092806544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092806736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092805584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092800208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092806352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092808272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092808848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092809040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092807888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092802512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092808656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092810576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092810192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093286544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093285968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092809424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092804816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093288080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093288656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093288848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093287696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093286160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093288464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093290384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093290960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093291152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093290000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093286928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093290768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093292688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093293264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093293456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093292304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093286736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093293072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093294992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093295568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093295760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093294608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093289232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093295376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093297296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093297872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093298064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093296912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093291536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093297680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093299600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093300176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093300368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093299216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093293840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093299984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091698640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091699216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091699408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091698256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091697872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091699024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091700944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091701520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091701712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091700560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091697488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091701328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091703248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091703824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093301904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093301520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091697104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091697680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093300752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373093298448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091704016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091702864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091697296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091703632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091705552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091706128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091706320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091705168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091699792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091705936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091707856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091708432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091708624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091707472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091702096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091708240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091710160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091710736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091710928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091709776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091704400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091710544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091712464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091712656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091712848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092122704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091711312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373091709008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092124432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092125008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092125200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092124048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092123664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092124816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092126736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092127312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092127504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092126352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092122896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092127120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092129040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092129616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092127888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  140373092130768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n✅ fold_0_final_tf/ folder created\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import tensorflow as tf, keras, pandas as pd\n\ntest_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/sample_submission_2.csv\")\ntest_df[\"Image_name\"] = test_df[\"Image_name\"].astype(str)\ntest_generator = XRayDataGenerator(\n    test_df, batch_size=BATCH_SIZE, img_size=IMG_SIZE, is_test=True\n)\n\n# 1️⃣ Load the exported SavedModel as a layer\ntfsml = keras.layers.TFSMLayer(\"fold_0_final_tf\", call_endpoint=\"serving_default\")\n\n# 2️⃣ Create an Input that matches the generator dtype (float32)\ninp32 = keras.Input(shape=(224, 224, 3), dtype=tf.float32)\n\n# 3️⃣ Cast to float16 before calling the SavedModel\ninp16 = tf.cast(inp32, tf.float16)\nout = tfsml(inp16)\n\n# 4️⃣ Wrap it up\nmodel = keras.Model(inp32, out)\n\n# 5️⃣ Predict\npreds = model.predict(test_generator, verbose=1)\n\nsubmission = pd.DataFrame(preds, columns=conditions)\nsubmission.insert(0, \"Image_name\", test_df[\"Image_name\"].values)\nsubmission.to_csv(\"submission_fold0.csv\", index=False)\nprint(\"✅ submission_fold0.csv created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:50:28.234724Z","iopub.execute_input":"2025-10-06T14:50:28.235337Z","iopub.status.idle":"2025-10-06T14:50:34.350433Z","shell.execute_reply.started":"2025-10-06T14:50:28.235315Z","shell.execute_reply":"2025-10-06T14:50:34.349453Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2932931066.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 3️⃣ Cast to float16 before calling the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0minp16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfsml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"],"ename":"ValueError","evalue":"A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:46:32.816578Z","iopub.execute_input":"2025-10-06T14:46:32.816837Z","iopub.status.idle":"2025-10-06T14:46:32.832792Z","shell.execute_reply.started":"2025-10-06T14:46:32.816820Z","shell.execute_reply":"2025-10-06T14:46:32.832089Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_3 (\u001b[38;5;33mCast\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tfsm_layer (\u001b[38;5;33mTFSMLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │    \u001b[38;5;34m24,115,854\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cast_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ tfsm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TFSMLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">24,115,854</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,115,854\u001b[0m (91.99 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,115,854</span> (91.99 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,062,734\u001b[0m (91.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,062,734</span> (91.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# test_df = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/sample_submission_2.csv\")\n# test_df[\"Image_name\"] = test_df[\"Image_name\"].astype(str)\n\n# test_generator = XRayDataGenerator(test_df, batch_size=32, is_test=True)\n# preds = model.predict(test_generator, verbose=1)\n\n# submission = pd.DataFrame(preds, columns=conditions)\n# submission.insert(0, \"Image_name\", test_df[\"Image_name\"].values) # start, column, \n# submission.to_csv(\"submission.csv\", index=False)\n\n# print(\"✅ Submission file created successfully: submission.csv\")\n# print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T14:48:32.752057Z","iopub.execute_input":"2025-10-06T14:48:32.752781Z","iopub.status.idle":"2025-10-06T14:48:32.756165Z","shell.execute_reply.started":"2025-10-06T14:48:32.752760Z","shell.execute_reply":"2025-10-06T14:48:32.755437Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
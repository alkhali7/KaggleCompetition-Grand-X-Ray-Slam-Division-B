{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Improved ResNet","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:03.377226Z","iopub.execute_input":"2025-10-06T04:50:03.377713Z","iopub.status.idle":"2025-10-06T04:50:04.190559Z","shell.execute_reply.started":"2025-10-06T04:50:03.377692Z","shell.execute_reply":"2025-10-06T04:50:04.189772Z"}},"outputs":[{"name":"stdout","text":"GPUs Available: 1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.applications.resnet50 as resnet\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:39.273818Z","iopub.execute_input":"2025-10-06T04:50:39.274572Z","iopub.status.idle":"2025-10-06T04:50:39.280869Z","shell.execute_reply.started":"2025-10-06T04:50:39.274549Z","shell.execute_reply":"2025-10-06T04:50:39.280015Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:53:09.565957Z","iopub.execute_input":"2025-10-06T04:53:09.566273Z","iopub.status.idle":"2025-10-06T04:53:13.081426Z","shell.execute_reply.started":"2025-10-06T04:53:09.566246Z","shell.execute_reply":"2025-10-06T04:53:13.080566Z"}},"outputs":[{"name":"stdout","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\nDownloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.9\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:42.222397Z","iopub.execute_input":"2025-10-06T04:50:42.222663Z","iopub.status.idle":"2025-10-06T04:50:42.229797Z","shell.execute_reply.started":"2025-10-06T04:50:42.222643Z","shell.execute_reply":"2025-10-06T04:50:42.229021Z"}},"outputs":[{"name":"stdout","text":"['grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:42.833735Z","iopub.execute_input":"2025-10-06T04:50:42.834026Z","iopub.status.idle":"2025-10-06T04:50:43.160050Z","shell.execute_reply.started":"2025-10-06T04:50:42.834005Z","shell.execute_reply":"2025-10-06T04:50:43.159243Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()   # train data encoded\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:  # features that can be encoded\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values\nprint(X.shape) # 4 features (ViewCategory, ViewPosition, Age, Sex)\nprint(y.shape)  # 14 conditions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:43.516750Z","iopub.execute_input":"2025-10-06T04:50:43.517055Z","iopub.status.idle":"2025-10-06T04:50:43.597784Z","shell.execute_reply.started":"2025-10-06T04:50:43.517032Z","shell.execute_reply":"2025-10-06T04:50:43.597014Z"}},"outputs":[{"name":"stdout","text":"(108494, 4)\n(108494, 14)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral; since ViewCategory is unbalanced\n\n# One-hot encode ViewCategory and append to \nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix (added ViewCategory as y to stratify and reduce bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:50:44.696587Z","iopub.execute_input":"2025-10-06T04:50:44.697153Z","iopub.status.idle":"2025-10-06T04:50:44.717709Z","shell.execute_reply.started":"2025-10-06T04:50:44.697127Z","shell.execute_reply":"2025-10-06T04:50:44.717039Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# ‚ö° GPU-Optimized GRAND X-RAY SLAM ‚Äî ResNet50 AUC Pipeline\n# ============================================================\nimport os, gc\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers.schedules import CosineDecayRestarts\nfrom tensorflow.keras import mixed_precision\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n# Enable GPU optimizations\ntf.config.optimizer.set_jit(True)\ntf.config.experimental.enable_tensor_float_32_execution(True)\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"‚úÖ Mixed precision + XLA enabled for faster GPU performance.\")\n\n# ============================================================\n# ü™Ñ Dataset Preprocessing (tf.data pipeline)\n# ============================================================\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\n\ndef decode_image(filename, label=None, augment=False):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.keras.applications.resnet50.preprocess_input(img)\n\n    if augment:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.1)\n    return (img, label) if label is not None else img\n\ndef make_dataset(df, is_test=False, augment=False):\n    img_paths = (\"/kaggle/input/grand-xray-slam-division-b/test2/\" + df[\"Image_name\"]) if is_test else (\"/kaggle/input/grand-xray-slam-division-b/train2/\" + df[\"Image_name\"])\n    labels = None if is_test else df[conditions].values.astype(np.float32)\n    \n    ds = tf.data.Dataset.from_tensor_slices((img_paths, labels) if not is_test else img_paths)\n    if not is_test:\n        ds = ds.map(lambda x, y: decode_image(x, y, augment), num_parallel_calls=tf.data.AUTOTUNE)\n    else:\n        ds = ds.map(lambda x: decode_image(x, None, False), num_parallel_calls=tf.data.AUTOTUNE)\n    \n    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\nprint('**********Building ResNet Model******************')\n# ============================================================\n# üß± Build ResNet50 model\n# ============================================================\ndef build_resnet_model(num_classes=14, unfreeze_layers=None):\n    base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n    if unfreeze_layers:\n        for layer in base.layers[-unfreeze_layers:]:\n            layer.trainable = True\n    else:\n        base.trainable = False\n\n    x = tf.keras.layers.GlobalAveragePooling2D()(base.output)\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    out = tf.keras.layers.Dense(num_classes, activation=\"sigmoid\")(x)\n    return tf.keras.Model(inputs=base.input, outputs=out)\n\n# ============================================================\n# ‚öôÔ∏è Callbacks\n# ============================================================\ndef get_callbacks(fold):\n    return [\n        ModelCheckpoint(f\"fold_{fold}_best.h5\", monitor=\"val_AUC\", mode=\"max\", save_best_only=True, verbose=1),\n        EarlyStopping(monitor=\"val_AUC\", mode=\"max\", patience=5, restore_best_weights=True, verbose=1),\n    ]\n\n# ============================================================\n# üöÄ Cross-validation training loop\n# ============================================================\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfold_aucs = []\nprint('**********Starting MSKF (k-fold)******************')\n\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    print(f\"\\n================ FOLD {fold+1} ================\")\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n\n    # tf.data datasets instead of Sequence\n    train_ds = make_dataset(train_df, augment=True)\n    val_ds   = make_dataset(val_df)\n\n    # Learning rate schedule\n    lr_schedule = CosineDecayRestarts(\n        initial_learning_rate=1e-4,\n        first_decay_steps=len(train_ds)*2,\n        t_mul=2.0, m_mul=0.9, alpha=1e-6\n    )\n\n    # Stage 1 ‚Äî Train top layers\n    model = build_resnet_model()\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n                  loss=\"binary_crossentropy\",\n                  metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n    history = model.fit(train_ds, validation_data=val_ds, epochs=3, callbacks=get_callbacks(fold), verbose=1)\n    \n    # Stage 2 ‚Äî Fine-tune last 20 layers\n    for layer in model.layers[-20:]: layer.trainable = True\n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                  loss=\"binary_crossentropy\",\n                  metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n    history_ft = model.fit(train_ds, validation_data=val_ds, epochs=3, callbacks=get_callbacks(fold), verbose=1)\n\n    # Save final model per fold\n    model.save(f\"fold_{fold}_final.h5\")\n    best_auc = max(history.history['val_auc'] + history_ft.history['val_AUC'])\n    fold_aucs.append(best_auc)\n    print(f\"‚úÖ Fold {fold+1} Best AUC: {best_auc:.4f}\")\n    gc.collect()\nprint('*************************MSKF K-FOld COMPLETE*************')\n# ============================================================\n# üßæ CV Summary\n# ============================================================\nprint(f\"\\nüìä Cross-validation AUCs: {fold_aucs}\")\nprint(f\"üèÜ Mean CV AUC: {np.mean(fold_aucs):.4f}\")\n\n# ============================================================\n# üîÆ Ensemble predictions (mean of 5 folds)\n# ============================================================\nprint(\"\\nGenerating final ensemble predictions...\")\ntest_ds = make_dataset(test_df, is_test=True)\nfold_preds = []\n\nfor fold in range(5):\n    m = tf.keras.models.load_model(f\"fold_{fold}_best.h5\", compile=False)\n    fold_preds.append(m.predict(test_ds, verbose=1))\n\nfinal_preds = np.mean(fold_preds, axis=0)\nsubmission = pd.DataFrame(final_preds, columns=conditions)\nsubmission.insert(0, \"Image_name\", test_df[\"Image_name\"].values)\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"‚úÖ submission.csv created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T04:53:17.662782Z","iopub.execute_input":"2025-10-06T04:53:17.663606Z","iopub.status.idle":"2025-10-06T05:03:48.529865Z","shell.execute_reply.started":"2025-10-06T04:53:17.663576Z","shell.execute_reply":"2025-10-06T05:03:48.528155Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Mixed precision + XLA enabled for faster GPU performance.\n**********Building ResNet Model******************\n**********Starting MSKF (k-fold)******************\n\n================ FOLD 1 ================\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1759726400.210403      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759726420.906564      87 service.cc:148] XLA service 0x7fab88012de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1759726420.907315      87 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1759726423.249802      87 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   3/2713\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:08\u001b[0m 48ms/step - auc: 0.4855 - loss: 1.0437   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1759726428.359804      87 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1035/2713\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m16:12\u001b[0m 580ms/step - auc: 0.7704 - loss: 0.5591","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3936290671.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                   metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m# Stage 2 ‚Äî Fine-tune last 20 layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node DecodeJpeg defined at (most recent call last):\n<stack traces unavailable>\nDetected at node DecodeJpeg defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input is empty.\n\t [[{{node DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Input is empty.\n\t [[{{node DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_13164]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node DecodeJpeg defined at (most recent call last):\n<stack traces unavailable>\nDetected at node DecodeJpeg defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input is empty.\n\t [[{{node DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Input is empty.\n\t [[{{node DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_13164]","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"},{"sourceId":13253858,"sourceType":"datasetVersion","datasetId":8398667}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet Model: \n- Multi-Label Stratified K-Fold\n    - Multi-label imbalance handled: All rare diseases are proportionally represented.\n    - View imbalance handled: Each fold has close to the same Frontal/Lateral distribution.\n    - Sex & Age: Since they’re balanced already, we don’t need to augment stratification with them.\n\n- Data Generator (train ML model in batches to increase time efficiency, since training data >100gb)\n- ResNet Model: fine tuned and pre-trained","metadata":{}},{"cell_type":"code","source":"# Imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport cv2\nimport os\nimport sys\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow as tf\nimport tensorflow.keras.applications.resnet50 as resnet\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:33:37.376999Z","iopub.execute_input":"2025-10-03T18:33:37.377325Z","iopub.status.idle":"2025-10-03T18:33:58.553035Z","shell.execute_reply.started":"2025-10-03T18:33:37.377300Z","shell.execute_reply":"2025-10-03T18:33:58.551662Z"}},"outputs":[{"name":"stderr","text":"2025-10-03 18:33:40.048623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759516420.392023      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759516420.488993      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input\"))\n\n# Path to competition dataset\ndata_dir = \"/kaggle/input/grand-xray-slam-division-b\"\n# Check what files are inside\nprint('Filenames of the data', os.listdir(data_dir))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T17:25:08.044926Z","iopub.execute_input":"2025-10-03T17:25:08.045285Z","iopub.status.idle":"2025-10-03T17:25:08.055881Z","shell.execute_reply.started":"2025-10-03T17:25:08.045258Z","shell.execute_reply":"2025-10-03T17:25:08.054862Z"}},"outputs":[{"name":"stdout","text":"['grand-xray-slam-division-b']\nFilenames of the data ['test2', 'sample_submission_2.csv', 'train2.csv', 'train2']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load the training CSV metadata with labels\ntrain = pd.read_csv(\"/kaggle/input/grand-xray-slam-division-b/train2.csv\")\n\nprint('Metadata shape:',train.shape)\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T17:55:17.159322Z","iopub.execute_input":"2025-10-03T17:55:17.159746Z","iopub.status.idle":"2025-10-03T17:55:17.684724Z","shell.execute_reply.started":"2025-10-03T17:55:17.159717Z","shell.execute_reply":"2025-10-03T17:55:17.683389Z"}},"outputs":[{"name":"stdout","text":"Metadata shape: (108494, 21)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"             Image_name  Patient_ID  Study     Sex   Age ViewCategory  \\\n0  00000003_001_001.jpg           3      1    Male  41.0      Frontal   \n1  00000004_001_001.jpg           4      1  Female  20.0      Frontal   \n2  00000004_001_002.jpg           4      1  Female  20.0      Lateral   \n3  00000006_001_001.jpg           6      1  Female  42.0      Frontal   \n4  00000010_001_001.jpg          10      1  Female  50.0      Frontal   \n\n  ViewPosition  Atelectasis  Cardiomegaly  Consolidation  ...  \\\n0           AP            0             1              0  ...   \n1           PA            0             0              0  ...   \n2      Lateral            0             0              0  ...   \n3           AP            0             0              0  ...   \n4           PA            0             0              0  ...   \n\n   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                           1         0            0             1   \n1                           0         0            0             0   \n2                           0         0            0             0   \n3                           0         0            0             0   \n4                           0         0            0             0   \n\n   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0           0                 0              0          0             0   \n1           1                 0              0          0             0   \n2           1                 0              0          0             0   \n3           1                 0              0          0             0   \n4           1                 0              0          0             0   \n\n   Support Devices  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Patient_ID</th>\n      <th>Study</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>ViewCategory</th>\n      <th>ViewPosition</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>...</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000003_001_001.jpg</td>\n      <td>3</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>41.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000004_001_001.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000004_001_002.jpg</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>Lateral</td>\n      <td>Lateral</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000006_001_001.jpg</td>\n      <td>6</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>42.0</td>\n      <td>Frontal</td>\n      <td>AP</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000010_001_001.jpg</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>50.0</td>\n      <td>Frontal</td>\n      <td>PA</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# **Multi-Label Stratified Kfold**\n- Split to train and val data using multlabelKfold\n    - Multi-label imbalance handled: All rare diseases are proportionally represented.\n    - View imbalance handled: Each fold has close to the same Frontal/Lateral distribution.\n    - Sex & Age: Since they’re balanced already, we don’t need to augment stratification with them.","metadata":{}},{"cell_type":"code","source":"# cannot dowwnload iterstat for Multi-Label Kfold Sratification of data \n# Solution fetch and load Multi-Kfold stratification function in script manually, this way we get the same behavoir of stratification without the need of interent\n# https://github.com/trent-b/iterative-stratification/blob/master/iterstrat/ml_stratifiers.py\n\nclass MultilabelStratifiedKFold(_BaseKFold):\n    \"\"\"Multilabel stratified K-Folds cross-validator\n    Provides train/test indices to split multilabel data into train/test sets.\n    This cross-validation object is a variation of KFold that returns\n    stratified folds for multilabel data. The folds are made by preserving\n    the percentage of samples for each label.\n    Parameters\n    ----------\n    n_splits : int, default=3\n        Number of folds. Must be at least 2.\n    shuffle : boolean, optional\n        Whether to shuffle each stratification of the data before splitting\n        into batches.\n    random_state : int, RandomState instance or None, optional, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`. Unlike StratifiedKFold that only uses random_state\n        when ``shuffle`` == True, this multilabel implementation\n        always uses the random_state since the iterative stratification\n        algorithm breaks ties randomly.\n    Examples\n    --------\n    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n    >>> import numpy as np\n    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n    >>> mskf.get_n_splits(X, y)\n    2\n    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n    >>> for train_index, test_index in mskf.split(X, y):\n    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    ...    X_train, X_test = X[train_index], X[test_index]\n    ...    y_train, y_test = y[train_index], y[test_index]\n    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n    Notes\n    -----\n    Train and test sizes may be slightly different in each fold.\n    See also\n    --------\n    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n    n times.\n    \"\"\"\n\n    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n\n    def _make_test_folds(self, X, y):\n        y = np.asarray(y, dtype=bool)\n        type_of_target_y = type_of_target(y)\n\n        if type_of_target_y != 'multilabel-indicator':\n            raise ValueError(\n                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n\n        num_samples = y.shape[0]\n\n        rng = check_random_state(self.random_state)\n        indices = np.arange(num_samples)\n\n        if self.shuffle:\n            rng.shuffle(indices)\n            y = y[indices]\n\n        r = np.asarray([1 / self.n_splits] * self.n_splits)\n\n        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n\n        return test_folds[np.argsort(indices)]\n\n    def _iter_test_masks(self, X=None, y=None, groups=None):\n        test_folds = self._make_test_folds(X, y)\n        for i in range(self.n_splits):\n            yield test_folds == i\n\n    def split(self, X, y, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n            Note that providing ``y`` is sufficient to generate the splits and\n            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n            ``X`` instead of actual training data.\n        y : array-like, shape (n_samples, n_labels)\n            The target variable for supervised learning problems.\n            Multilabel stratification is done based on the y labels.\n        groups : object\n            Always ignored, exists for compatibility.\n        Returns\n        -------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        Notes\n        -----\n        Randomized CV splitters may return different results for each call of\n        split. You can make the results identical by setting ``random_state``\n        to an integer.\n        \"\"\"\n        y = check_array(y, ensure_2d=False, dtype=None)\n        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T17:52:58.062112Z","iopub.execute_input":"2025-10-03T17:52:58.067629Z","iopub.status.idle":"2025-10-03T17:52:58.094561Z","shell.execute_reply.started":"2025-10-03T17:52:58.067408Z","shell.execute_reply":"2025-10-03T17:52:58.092918Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# 1. Feature & Target Preperation\n# Define labels\nconditions = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n# Features you want\nfeatures = [\"ViewCategory\", \"ViewPosition\", \"Age\", \"Sex\"]\n\n# Encode categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_enc = train.copy()\nfor col in [\"ViewCategory\", \"ViewPosition\", \"Sex\"]:\n    le = LabelEncoder()\n    train_enc[col] = le.fit_transform(train[col].astype(str))\n\nX = train_enc[features].values\ny = train[conditions].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:24:06.707607Z","iopub.execute_input":"2025-10-03T18:24:06.708016Z","iopub.status.idle":"2025-10-03T18:24:06.827117Z","shell.execute_reply.started":"2025-10-03T18:24:06.707991Z","shell.execute_reply":"2025-10-03T18:24:06.825545Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# 2. Adding ViewBalancing for Stratification: ViewCategory= Frontal, Lateral\n\n# One-hot encode ViewCategory and append to y\nview_onehot = pd.get_dummies(train[\"ViewCategory\"], prefix=\"view\").values\n\ny_aug = np.hstack([y, view_onehot])  # augmented target matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:27:37.101966Z","iopub.execute_input":"2025-10-03T18:27:37.103458Z","iopub.status.idle":"2025-10-03T18:27:37.135796Z","shell.execute_reply.started":"2025-10-03T18:27:37.103404Z","shell.execute_reply":"2025-10-03T18:27:37.134273Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 3. Multilabel Stratified K-Fold Split\nmskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(mskf.split(X, y_aug)):\n    print(f\"Fold {fold}\")\n    print(\" Train:\", len(train_idx), \" Val:\", len(val_idx))\n\n    train_df = train.iloc[train_idx].reset_index(drop=True)\n    val_df   = train.iloc[val_idx].reset_index(drop=True)\n\n    # Check condition + view balance\n    print(\"  Train views:\", train_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Val views:\", val_df[\"ViewCategory\"].value_counts().to_dict())\n    print(\"  Train labels sum:\", train_df[conditions].sum().to_dict())\n    print(\"  Val labels sum:\", val_df[conditions].sum().to_dict())\n    print(\"-\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:29:00.760270Z","iopub.execute_input":"2025-10-03T18:29:00.760703Z","iopub.status.idle":"2025-10-03T18:29:04.114830Z","shell.execute_reply.started":"2025-10-03T18:29:00.760676Z","shell.execute_reply":"2025-10-03T18:29:04.113470Z"}},"outputs":[{"name":"stdout","text":"Fold 0\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27391, 'Pleural Effusion': 27655, 'Pleural Other': 5544, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6974, 'Pleural Effusion': 6914, 'Pleural Other': 1387, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 1\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23716, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27668, 'Pleural Effusion': 27656, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6991, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5928, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6697, 'Pleural Effusion': 6913, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1747, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 2\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21254, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11662, 'Lung Lesion': 9885, 'Lung Opacity': 39217, 'No Finding': 27408, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11452, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5313, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2916, 'Lung Lesion': 2472, 'Lung Opacity': 9805, 'No Finding': 6957, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2864, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 3\n Train: 86795  Val: 21699\n  Train views: {'Frontal': 76011, 'Lateral': 10784}\n  Val views: {'Frontal': 19003, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30890, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30053, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27423, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7723, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7513, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6942, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\nFold 4\n Train: 86796  Val: 21698\n  Train views: {'Frontal': 76012, 'Lateral': 10784}\n  Val views: {'Frontal': 19002, 'Lateral': 2696}\n  Train labels sum: {'Atelectasis': 30891, 'Cardiomegaly': 27984, 'Consolidation': 23715, 'Edema': 21253, 'Enlarged Cardiomediastinum': 30052, 'Fracture': 11663, 'Lung Lesion': 9886, 'Lung Opacity': 39218, 'No Finding': 27570, 'Pleural Effusion': 27655, 'Pleural Other': 5545, 'Pneumonia': 11453, 'Pneumothorax': 6990, 'Support Devices': 29908}\n  Val labels sum: {'Atelectasis': 7722, 'Cardiomegaly': 6996, 'Consolidation': 5929, 'Edema': 5314, 'Enlarged Cardiomediastinum': 7514, 'Fracture': 2915, 'Lung Lesion': 2471, 'Lung Opacity': 9804, 'No Finding': 6795, 'Pleural Effusion': 6914, 'Pleural Other': 1386, 'Pneumonia': 2863, 'Pneumothorax': 1748, 'Support Devices': 7477}\n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(train_df.shape)\nprint(val_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:32:00.137766Z","iopub.execute_input":"2025-10-03T18:32:00.138130Z","iopub.status.idle":"2025-10-03T18:32:00.144932Z","shell.execute_reply.started":"2025-10-03T18:32:00.138104Z","shell.execute_reply":"2025-10-03T18:32:00.143412Z"}},"outputs":[{"name":"stdout","text":"(86796, 21)\n(21698, 21)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Data Generator\nTo handle large datasets, we use a custom generator to load images in batches.\n\nEach image is preprocessed with ResNet-50’s preprocessing function and resized to 224×224 (the default input size for ResNet-50).","metadata":{}},{"cell_type":"code","source":"class XRayDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size=32, img_size=(224, 224), is_test=False, **kwargs):\n        super().__init__(**kwargs)\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.is_test = is_test\n        self.image_dir = '/kaggle/input/grand-xray-slam-division-b/train2/' if not is_test else '/kaggle/input/grand-xray-slam-division-b/test2/'\n        self.conditions = conditions\n        \n        if not os.path.exists(self.image_dir):\n            print(f\"Error: Directory {self.image_dir} not found.\")\n            raise FileNotFoundError(f\"Directory {self.image_dir} missing.\")\n    \n    def __len__(self):\n        return (len(self.dataframe) + self.batch_size - 1) // self.batch_size\n    \n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min(start + self.batch_size, len(self.dataframe))\n        batch_data = self.dataframe.iloc[start:end]\n        \n        images, labels = [], []\n        \n        for _, row in batch_data.iterrows():\n            img_path = os.path.join(self.image_dir, row['Image_name'])\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            \n            if img is not None and img.shape[0] > 0 and img.shape[1] > 0:\n                img = cv2.resize(img, self.img_size)\n                img = resnet.preprocess_input(img)\n                images.append(img)\n                \n                if not self.is_test:\n                    labels.append(row[self.conditions].values.astype(np.float32))\n        \n        if not images:\n            dummy_img = np.zeros((*self.img_size, 3), dtype=np.float32)\n            images.append(dummy_img)\n            if not self.is_test:\n                labels.append(np.zeros(len(self.conditions), dtype=np.float32))\n        \n        if not self.is_test:\n            return np.array(images), np.array(labels)\n        else:\n            return np.array(images)\n\n# Create generators\nbatch_size = 32\ntrain_generator = XRayDataGenerator(train_df, batch_size=batch_size)\nval_generator = XRayDataGenerator(val_df, batch_size=batch_size)\nprint(\"Data generators created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T18:34:27.104998Z","iopub.execute_input":"2025-10-03T18:34:27.105315Z","iopub.status.idle":"2025-10-03T18:34:27.137235Z","shell.execute_reply.started":"2025-10-03T18:34:27.105293Z","shell.execute_reply":"2025-10-03T18:34:27.136004Z"}},"outputs":[{"name":"stdout","text":"Data generators created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Build ResNet-50 Model¶\nWe load a pretrained ResNet-50 model with weights from ImageNet.\nThe convolutional base is frozen to retain pretrained features, and we add a custom classifier head:\n\n- Global Average Pooling to reduce feature maps.\n- Dense layer for feature learning.\n- Dropout to reduce overfitting.\n- Sigmoid output for multi-label classification across 14 chest conditions.","metadata":{}},{"cell_type":"code","source":"!ls -lh /kaggle/input/resnet-pretrainedmodel\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T19:03:36.290930Z","iopub.execute_input":"2025-10-03T19:03:36.292298Z","iopub.status.idle":"2025-10-03T19:03:36.447891Z","shell.execute_reply.started":"2025-10-03T19:03:36.292249Z","shell.execute_reply":"2025-10-03T19:03:36.446808Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import ResNet50\n\nweights_path = \"/kaggle/input/resnet-pretrainedmodel/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n\ndef build_efficientnet_model(num_classes=14):\n    # Load EfficientNetB0 with cached ImageNet weights\n    base_model = ResNet50(\n        # weights=\"imagenet\",  doesnt work in kaggle\n        weights = weights_path,\n        include_top=False, \n        input_shape=(224, 224, 3)\n    )\n    base_model.trainable = False   # freeze backbone for now\n    \n    inputs = base_model.input\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation=\"sigmoid\")(x)  # multilabel\n    \n    model = Model(inputs, outputs)\n    return model\n\n# Redirect stdout to avoid long logs\nold_stdout = sys.stdout\nsys.stdout = mystdout = StringIO()\n\nmodel = build_efficientnet_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss=\"binary_crossentropy\",\n    metrics=[\"AUC\"]\n)\n\n# Restore stdout\nsys.stdout = old_stdout\n\nprint(\"Model Architecture: EfficientNetB0 + Custom Head\")\nprint(f\"Total parameters: {model.count_params():,}\")\ntrainable_params = sum([tf.size(v).numpy() for v in model.trainable_variables])\nprint(f\"Trainable parameters: {trainable_params:,}\")\nprint(f\"Non-trainable parameters: {model.count_params() - trainable_params:,}\")\nprint(\"Model compiled successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T19:04:32.392334Z","iopub.execute_input":"2025-10-03T19:04:32.392811Z","iopub.status.idle":"2025-10-03T19:04:33.883426Z","shell.execute_reply.started":"2025-10-03T19:04:32.392769Z","shell.execute_reply":"2025-10-03T19:04:33.882065Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1446601902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmystdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_efficientnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m model.compile(\n\u001b[1;32m     32\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1446601902.py\u001b[0m in \u001b[0;36mbuild_efficientnet_model\u001b[0;34m(num_classes)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_efficientnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Load EfficientNetB0 with cached ImageNet weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     base_model = ResNet50(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# weights=\"imagenet\",  doesnt work in kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack_residual_blocks_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     return ResNet(\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mpreact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36m_set_weights\u001b[0;34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 )\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;34mf\"Shape mismatch in {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;34mf\"for weight {symbolic_weights[i].path}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape mismatch in layer #26 (named conv3_block1_0_conv)for weight conv3_block1_0_conv/kernel. Weight expects shape (1, 1, 256, 512). Received saved weight with shape (1, 1, 128, 512)"],"ename":"ValueError","evalue":"Shape mismatch in layer #26 (named conv3_block1_0_conv)for weight conv3_block1_0_conv/kernel. Weight expects shape (1, 1, 256, 512). Received saved weight with shape (1, 1, 128, 512)","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================\n# tpu_resnet_multilabel_training.py\n# ===============================\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\n\n# -------------------------\n# Label columns\n# -------------------------\nLABEL_COLUMNS = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\n# -------------------------\n# Dataset (3-channel images with augmentation)\n# -------------------------\nclass XRayDataset(Dataset):\n    def __init__(self, df, image_dir, img_size=(512,512), augment=False):\n        self.df = df.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.img_size = img_size\n        self.augment = augment\n\n        if augment:\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(),\n                transforms.RandomRotation(15),\n                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.485, 0.485], [0.229, 0.229, 0.229])\n            ])\n        else:\n            self.transform = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize(img_size),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.485, 0.485], [0.229, 0.229, 0.229])\n            ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.image_dir, row['Image_name'])\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        if img is None:\n            img = np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.uint8)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.transform(img)\n        labels = row[LABEL_COLUMNS].values.astype(np.float32)\n        return img, torch.tensor(labels, dtype=torch.float32)\n\n# -------------------------\n# Weighted Focal Loss\n# -------------------------\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        if self.alpha is not None:\n            BCE_loss = self.alpha.to(inputs.device) * BCE_loss\n        F_loss = (1-pt)**self.gamma * BCE_loss\n        if self.reduction == 'mean':\n            return F_loss.mean()\n        else:\n            return F_loss.sum()\n\n# -------------------------\n# Hybrid Loss (Focal + BCE)\n# -------------------------\nclass HybridLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0, focal_weight=0.5):\n        super().__init__()\n        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n        self.bce = nn.BCEWithLogitsLoss(pos_weight=alpha)\n        self.focal_weight = focal_weight\n\n    def forward(self, inputs, targets):\n        focal_loss = self.focal(inputs, targets)\n        bce_loss = self.bce(inputs, targets)\n        return self.focal_weight * focal_loss + (1 - self.focal_weight) * bce_loss\n\n# -------------------------\n# Main Training\n# -------------------------\nif __name__ == \"__main__\":\n    print(\"================================================\")\n    # -------------------------\n    # Paths\n    # -------------------------\n    TRAIN_CSV = \"/kaggle/input/grand-xray-slam-division-b/train2.csv\"\n    TRAIN_DIR = \"/kaggle/input/grand-xray-slam-division-b/train2\"\n\n    # -------------------------\n    # Load CSV and convert labels to numeric\n    # -------------------------\n    train_df = pd.read_csv(TRAIN_CSV)\n    train_df[LABEL_COLUMNS] = train_df[LABEL_COLUMNS].apply(pd.to_numeric, errors='coerce').fillna(0)\n\n    # -------------------------\n    # Compute class weights\n    # -------------------------\n    pos_counts = train_df[LABEL_COLUMNS].sum()\n    neg_counts = len(train_df) - pos_counts\n    class_weights = torch.tensor((neg_counts / (pos_counts + 1e-6)).values, dtype=torch.float32)\n\n    # -------------------------\n    # Dataset and DataLoader\n    # -------------------------\n    dataset = XRayDataset(train_df, TRAIN_DIR, img_size=(224,224), augment=True)\n    loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)  # adjusted for 512x512\n\n    # -------------------------\n    # TPU Device and Loader\n    # -------------------------\n    device = xm.xla_device()\n    loader = pl.MpDeviceLoader(loader, device)\n    print(\"Using TPU device:\", device)\n\n    # -------------------------\n    # Model\n    # -------------------------\n    from torchvision.models import resnet152, ResNet152_Weights\n    model = resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)\n    model.fc = nn.Linear(2048, len(LABEL_COLUMNS))\n    model.to(device)\n\n    # -------------------------\n    # Optimizer & Loss\n    # -------------------------\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    criterion = HybridLoss(alpha=class_weights, focal_weight=0.6)\n\n    # -------------------------\n    # Training loop\n    # -------------------------\n    num_epochs = 5\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        tqdm_loader = tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n\n        for imgs, labels in tqdm_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            xm.optimizer_step(optimizer)\n\n            total_loss += loss.item()\n            tqdm_loader.set_postfix({\"loss\": total_loss/(tqdm_loader.n+1)})\n\n        print(f\"Epoch {epoch+1} completed. Avg Loss: {total_loss/len(loader):.4f}\")\n\n        import numpy as np\n        import torch\n        from sklearn.metrics import roc_auc_score\n        all_labels = torch.cat(tuple(labels), dim=0).cpu().numpy()\n        all_preds = torch.cat(tuple(outputs), dim=0).detach().cpu().numpy()\n        try:\n            auc = roc_auc_score(all_labels, all_preds, average='macro')\n        except ValueError:\n            auc = float('nan')\n\n        # Print results\n        print(f\"\\nEpoch {epoch + 1}/{num_epochs} Summary:\")\n        print(f\"Avg Loss: {total_loss / len(loader):.4f}\")\n        print(f\"ROC AUC: {auc:.4f}\\n\")\n\n    print(\"Training completed on TPU cores!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:14:39.085660Z","iopub.execute_input":"2025-10-09T01:14:39.085807Z","iopub.status.idle":"2025-10-09T03:12:47.814410Z","shell.execute_reply.started":"2025-10-09T01:14:39.085791Z","shell.execute_reply":"2025-10-09T03:12:47.813124Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/torch_xla/__init__.py:258: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"================================================\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_10/1889971629.py:140: DeprecationWarning: Use torch_xla.device instead\n  device = xm.xla_device()\n","output_type":"stream"},{"name":"stdout","text":"Using TPU device: xla:0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1759972506.158885      10 common_lib.cc:648] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:238\n","output_type":"stream"},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-f82ba261.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 230M/230M [00:00<00:00, 256MB/s] \nEpoch 1/5:   0%|          | 0/1696 [00:00<?, ?batch/s]/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\nEpoch 1/5: 100%|██████████| 1696/1696 [31:57<00:00,  1.13s/batch, loss=0.517] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 completed. Avg Loss: 0.5170\n\nEpoch 1/5 Summary:\nAvg Loss: 0.5170\nROC AUC: 0.8761\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 1696/1696 [20:55<00:00,  1.35batch/s, loss=0.465]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 completed. Avg Loss: 0.4649\n\nEpoch 2/5 Summary:\nAvg Loss: 0.4649\nROC AUC: 0.9179\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 1696/1696 [21:24<00:00,  1.32batch/s, loss=0.448]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 completed. Avg Loss: 0.4479\n\nEpoch 3/5 Summary:\nAvg Loss: 0.4479\nROC AUC: 0.8935\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 1696/1696 [21:43<00:00,  1.30batch/s, loss=0.437]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 completed. Avg Loss: 0.4366\n\nEpoch 4/5 Summary:\nAvg Loss: 0.4366\nROC AUC: 0.9688\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 1696/1696 [21:26<00:00,  1.32batch/s, loss=0.427]","output_type":"stream"},{"name":"stdout","text":"Epoch 5 completed. Avg Loss: 0.4268\n\nEpoch 5/5 Summary:\nAvg Loss: 0.4268\nROC AUC: 0.9532\n\nTraining completed on TPU cores!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# =========================\n# Inference & Submission\n# =========================\nif __name__ == \"__main__\":\n    # -------------------------\n    # Test Set Path\n    # -------------------------\n    TEST_DIR = \"/kaggle/input/grand-xray-slam-division-b/test2\"\n\n    # -------------------------\n    # Create Test Dataset\n    # -------------------------\n    class TestDataset(Dataset):\n        def __init__(self, image_dir, img_size=(224,224)):\n            self.image_dir = image_dir\n            self.img_size = img_size\n            self.images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n            self.transform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.485, 0.485], [0.229, 0.229, 0.229])\n            ])\n\n        def __len__(self):\n            return len(self.images)\n\n        def __getitem__(self, idx):\n            img_name = self.images[idx]\n            img_path = os.path.join(self.image_dir, img_name)\n            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n            if img is None:\n                img = np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.uint8)\n            img = cv2.resize(img, self.img_size)\n            img = img.astype(np.float32) / 255.0\n            img = self.transform(img)\n            return img_name, img\n\n    # -------------------------\n    # Test Loader\n    # -------------------------\n    test_dataset = TestDataset(TEST_DIR)\n    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n    test_loader = pl.MpDeviceLoader(test_loader, device)\n\n    # -------------------------\n    # Inference\n    # -------------------------\n    model.eval()\n    submission = []\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Inference\"):\n            img_names, imgs = batch\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n\n            for name, prob in zip(img_names, probs):\n                row = [name] + prob.tolist()\n                submission.append(row)\n\n    # -------------------------\n    # Save Submission\n    # -------------------------\n    submission_df = pd.DataFrame(submission, columns=[\"Image_name\"] + LABEL_COLUMNS)\n    SUBMISSION_CSV = \"/kaggle/working/submission.csv\"\n    submission_df.to_csv(SUBMISSION_CSV, index=False)\n    print(f\"Submission file saved to {SUBMISSION_CSV}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T03:12:47.815282Z","iopub.execute_input":"2025-10-09T03:12:47.815832Z","iopub.status.idle":"2025-10-09T03:22:36.167301Z","shell.execute_reply.started":"2025-10-09T03:12:47.815813Z","shell.execute_reply":"2025-10-09T03:22:36.166084Z"}},"outputs":[{"name":"stderr","text":"Inference: 100%|██████████| 749/749 [09:46<00:00,  1.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Submission file saved to /kaggle/working/submission.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T03:22:36.169657Z","iopub.execute_input":"2025-10-09T03:22:36.169851Z","iopub.status.idle":"2025-10-09T03:22:36.194910Z","shell.execute_reply.started":"2025-10-09T03:22:36.169829Z","shell.execute_reply":"2025-10-09T03:22:36.194170Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                 Image_name  Atelectasis  Cardiomegaly  Consolidation  \\\n0      00000002_001_001.jpg     0.588338      0.533304       0.420442   \n1      00000002_001_002.jpg     0.537321      0.480841       0.522963   \n2      00000002_002_001.jpg     0.477501      0.475001       0.377278   \n3      00000008_001_001.jpg     0.549936      0.436892       0.395875   \n4      00000008_002_001.jpg     0.522037      0.371948       0.347818   \n...                     ...          ...           ...            ...   \n47922  20009239_009_000.jpg     0.459558      0.054689       0.335621   \n47923  20009239_010_000.jpg     0.404337      0.032144       0.279932   \n47924  20009239_011_000.jpg     0.442121      0.021986       0.230720   \n47925  20009239_012_000.jpg     0.431989      0.047798       0.256906   \n47926  20009239_013_000.jpg     0.357244      0.035637       0.271331   \n\n          Edema  Enlarged Cardiomediastinum  Fracture  Lung Lesion  \\\n0      0.383140                    0.618749  0.535954     0.318367   \n1      0.443063                    0.541917  0.624062     0.493039   \n2      0.369730                    0.495254  0.528144     0.330540   \n3      0.345480                    0.540365  0.595596     0.374730   \n4      0.280848                    0.438411  0.601109     0.321890   \n...         ...                         ...       ...          ...   \n47922  0.038043                    0.019514  0.183478     0.425327   \n47923  0.060307                    0.002514  0.017291     0.339331   \n47924  0.033964                    0.000618  0.005011     0.340831   \n47925  0.052510                    0.006022  0.039037     0.372614   \n47926  0.070284                    0.004012  0.022960     0.398723   \n\n       Lung Opacity  No Finding  Pleural Effusion  Pleural Other  Pneumonia  \\\n0          0.631151    0.220034          0.499770       0.295218   0.389012   \n1          0.627037    0.130759          0.477923       0.347875   0.489386   \n2          0.522241    0.155403          0.426558       0.301524   0.359055   \n3          0.550680    0.058653          0.463184       0.240875   0.338732   \n4          0.461097    0.049066          0.445307       0.206535   0.317135   \n...             ...         ...               ...            ...        ...   \n47922      0.383629    0.290678          0.400904       0.490137   0.216664   \n47923      0.346398    0.410858          0.458241       0.361558   0.111223   \n47924      0.304567    0.444894          0.350364       0.309063   0.063857   \n47925      0.347557    0.383492          0.396977       0.401870   0.138498   \n47926      0.341921    0.389407          0.349285       0.372194   0.114879   \n\n       Pneumothorax  Support Devices  \n0          0.324956         0.480835  \n1          0.430935         0.577663  \n2          0.359818         0.495589  \n3          0.613156         0.759055  \n4          0.650601         0.741227  \n...             ...              ...  \n47922      0.536702         0.019602  \n47923      0.404965         0.001718  \n47924      0.453756         0.000833  \n47925      0.480332         0.004249  \n47926      0.523138         0.003496  \n\n[47927 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_name</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000002_001_001.jpg</td>\n      <td>0.588338</td>\n      <td>0.533304</td>\n      <td>0.420442</td>\n      <td>0.383140</td>\n      <td>0.618749</td>\n      <td>0.535954</td>\n      <td>0.318367</td>\n      <td>0.631151</td>\n      <td>0.220034</td>\n      <td>0.499770</td>\n      <td>0.295218</td>\n      <td>0.389012</td>\n      <td>0.324956</td>\n      <td>0.480835</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000002_001_002.jpg</td>\n      <td>0.537321</td>\n      <td>0.480841</td>\n      <td>0.522963</td>\n      <td>0.443063</td>\n      <td>0.541917</td>\n      <td>0.624062</td>\n      <td>0.493039</td>\n      <td>0.627037</td>\n      <td>0.130759</td>\n      <td>0.477923</td>\n      <td>0.347875</td>\n      <td>0.489386</td>\n      <td>0.430935</td>\n      <td>0.577663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000002_002_001.jpg</td>\n      <td>0.477501</td>\n      <td>0.475001</td>\n      <td>0.377278</td>\n      <td>0.369730</td>\n      <td>0.495254</td>\n      <td>0.528144</td>\n      <td>0.330540</td>\n      <td>0.522241</td>\n      <td>0.155403</td>\n      <td>0.426558</td>\n      <td>0.301524</td>\n      <td>0.359055</td>\n      <td>0.359818</td>\n      <td>0.495589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000008_001_001.jpg</td>\n      <td>0.549936</td>\n      <td>0.436892</td>\n      <td>0.395875</td>\n      <td>0.345480</td>\n      <td>0.540365</td>\n      <td>0.595596</td>\n      <td>0.374730</td>\n      <td>0.550680</td>\n      <td>0.058653</td>\n      <td>0.463184</td>\n      <td>0.240875</td>\n      <td>0.338732</td>\n      <td>0.613156</td>\n      <td>0.759055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000008_002_001.jpg</td>\n      <td>0.522037</td>\n      <td>0.371948</td>\n      <td>0.347818</td>\n      <td>0.280848</td>\n      <td>0.438411</td>\n      <td>0.601109</td>\n      <td>0.321890</td>\n      <td>0.461097</td>\n      <td>0.049066</td>\n      <td>0.445307</td>\n      <td>0.206535</td>\n      <td>0.317135</td>\n      <td>0.650601</td>\n      <td>0.741227</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47922</th>\n      <td>20009239_009_000.jpg</td>\n      <td>0.459558</td>\n      <td>0.054689</td>\n      <td>0.335621</td>\n      <td>0.038043</td>\n      <td>0.019514</td>\n      <td>0.183478</td>\n      <td>0.425327</td>\n      <td>0.383629</td>\n      <td>0.290678</td>\n      <td>0.400904</td>\n      <td>0.490137</td>\n      <td>0.216664</td>\n      <td>0.536702</td>\n      <td>0.019602</td>\n    </tr>\n    <tr>\n      <th>47923</th>\n      <td>20009239_010_000.jpg</td>\n      <td>0.404337</td>\n      <td>0.032144</td>\n      <td>0.279932</td>\n      <td>0.060307</td>\n      <td>0.002514</td>\n      <td>0.017291</td>\n      <td>0.339331</td>\n      <td>0.346398</td>\n      <td>0.410858</td>\n      <td>0.458241</td>\n      <td>0.361558</td>\n      <td>0.111223</td>\n      <td>0.404965</td>\n      <td>0.001718</td>\n    </tr>\n    <tr>\n      <th>47924</th>\n      <td>20009239_011_000.jpg</td>\n      <td>0.442121</td>\n      <td>0.021986</td>\n      <td>0.230720</td>\n      <td>0.033964</td>\n      <td>0.000618</td>\n      <td>0.005011</td>\n      <td>0.340831</td>\n      <td>0.304567</td>\n      <td>0.444894</td>\n      <td>0.350364</td>\n      <td>0.309063</td>\n      <td>0.063857</td>\n      <td>0.453756</td>\n      <td>0.000833</td>\n    </tr>\n    <tr>\n      <th>47925</th>\n      <td>20009239_012_000.jpg</td>\n      <td>0.431989</td>\n      <td>0.047798</td>\n      <td>0.256906</td>\n      <td>0.052510</td>\n      <td>0.006022</td>\n      <td>0.039037</td>\n      <td>0.372614</td>\n      <td>0.347557</td>\n      <td>0.383492</td>\n      <td>0.396977</td>\n      <td>0.401870</td>\n      <td>0.138498</td>\n      <td>0.480332</td>\n      <td>0.004249</td>\n    </tr>\n    <tr>\n      <th>47926</th>\n      <td>20009239_013_000.jpg</td>\n      <td>0.357244</td>\n      <td>0.035637</td>\n      <td>0.271331</td>\n      <td>0.070284</td>\n      <td>0.004012</td>\n      <td>0.022960</td>\n      <td>0.398723</td>\n      <td>0.341921</td>\n      <td>0.389407</td>\n      <td>0.349285</td>\n      <td>0.372194</td>\n      <td>0.114879</td>\n      <td>0.523138</td>\n      <td>0.003496</td>\n    </tr>\n  </tbody>\n</table>\n<p>47927 rows × 15 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}